[youtube] Extracting URL: https://www.youtube.com/watch?v=C3TqcUEFR58
[START] Starting transcription: https://www.youtube.com/watch?v=C3TqcUEFR58
Engine: gpt-4o-mini-transcribe

Extracting video information...
Title: AI Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference
Duration: 3409 seconds
Uploader: MIT Stone Center on Inequality & Shaping Work

Downloading audio...
Downloading audio from YouTube...
[youtube] C3TqcUEFR58: Downloading webpage
[youtube] C3TqcUEFR58: Downloading tv simply player API JSON
[youtube] C3TqcUEFR58: Downloading tv client config
[youtube] C3TqcUEFR58: Downloading tv player API JSON
[info] C3TqcUEFR58: Downloading 1 format(s): 251
[download] Sleeping 5.00 seconds as required by the site...
[download] Destination: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/AI Snake Oil： What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference [C3TqcUEFR58].webm

[download]   0.0% of   47.60MiB at  288.43KiB/s ETA 02:50
[download]   0.0% of   47.60MiB at  610.76KiB/s ETA 01:20
[download]   0.0% of   47.60MiB at    1.13MiB/s ETA 00:42
[download]   0.0% of   47.60MiB at    2.05MiB/s ETA 00:23
[download]   0.1% of   47.60MiB at  738.47KiB/s ETA 01:05
[download]   0.1% of   47.60MiB at  840.33KiB/s ETA 00:57
[download]   0.3% of   47.60MiB at    1.08MiB/s ETA 00:43
[download]   0.5% of   47.60MiB at    1.63MiB/s ETA 00:29
[download]   1.0% of   47.60MiB at    2.48MiB/s ETA 00:19
[download]   2.1% of   47.60MiB at    4.03MiB/s ETA 00:11
[download]   4.2% of   47.60MiB at    6.88MiB/s ETA 00:06
[download]   8.4% of   47.60MiB at   11.63MiB/s ETA 00:03
[download]  16.8% of   47.60MiB at   15.52MiB/s ETA 00:02
[download]  20.2% of   47.60MiB at   14.91MiB/s ETA 00:02
[download]  20.2% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  20.2% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  20.3% of   47.60MiB at    2.75MiB/s ETA 00:13  
[download]  20.3% of   47.60MiB at    4.53MiB/s ETA 00:08
[download]  20.3% of   47.60MiB at    8.02MiB/s ETA 00:04
[download]  20.4% of   47.60MiB at   14.90MiB/s ETA 00:02
[download]  20.5% of   47.60MiB at   28.69MiB/s ETA 00:01
[download]  20.8% of   47.60MiB at   53.38MiB/s ETA 00:00
[download]  21.3% of   47.60MiB at    8.43MiB/s ETA 00:04
[download]  22.3% of   47.60MiB at    7.88MiB/s ETA 00:04
[download]  24.4% of   47.60MiB at    7.83MiB/s ETA 00:04
[download]  28.6% of   47.60MiB at   12.62MiB/s ETA 00:02
[download]  37.0% of   47.60MiB at   14.78MiB/s ETA 00:02
[download]  40.7% of   47.60MiB at   16.26MiB/s ETA 00:01
[download]  40.7% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  40.7% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  40.7% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  40.7% of   47.60MiB at   12.41MiB/s ETA 00:02  
[download]  40.7% of   47.60MiB at   21.76MiB/s ETA 00:01
[download]  40.8% of   47.60MiB at   28.48MiB/s ETA 00:00
[download]  40.9% of   47.60MiB at   46.49MiB/s ETA 00:00
[download]  41.2% of   47.60MiB at   56.92MiB/s ETA 00:00
[download]  41.7% of   47.60MiB at   59.61MiB/s ETA 00:00
[download]  42.8% of   47.60MiB at   19.41MiB/s ETA 00:01
[download]  44.9% of   47.60MiB at   16.46MiB/s ETA 00:01
[download]  49.1% of   47.60MiB at   21.77MiB/s ETA 00:01
[download]  57.5% of   47.60MiB at   20.80MiB/s ETA 00:00
[download]  61.2% of   47.60MiB at   23.29MiB/s ETA 00:00
[download]  61.2% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  61.2% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  61.2% of   47.60MiB at  187.99KiB/s ETA 01:40  
[download]  61.2% of   47.60MiB at  399.80KiB/s ETA 00:47
[download]  61.3% of   47.60MiB at  822.30KiB/s ETA 00:22
[download]  61.3% of   47.60MiB at    1.61MiB/s ETA 00:11
[download]  61.5% of   47.60MiB at    3.23MiB/s ETA 00:05
[download]  61.7% of   47.60MiB at    6.45MiB/s ETA 00:02
[download]  62.3% of   47.60MiB at   12.81MiB/s ETA 00:01
[download]  63.3% of   47.60MiB at   18.86MiB/s ETA 00:00
[download]  65.4% of   47.60MiB at   16.59MiB/s ETA 00:00
[download]  69.6% of   47.60MiB at   20.25MiB/s ETA 00:00
[download]  78.0% of   47.60MiB at   29.32MiB/s ETA 00:00
[download]  81.8% of   47.60MiB at   32.69MiB/s ETA 00:00
[download]  81.8% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  81.8% of   47.60MiB at  Unknown B/s ETA Unknown
[download]  81.8% of   47.60MiB at    4.88MiB/s ETA 00:01  
[download]  81.8% of   47.60MiB at    9.35MiB/s ETA 00:00
[download]  81.8% of   47.60MiB at   17.33MiB/s ETA 00:00
[download]  81.9% of   47.60MiB at   28.74MiB/s ETA 00:00
[download]  82.0% of   47.60MiB at   53.00MiB/s ETA 00:00
[download]  82.3% of   47.60MiB at   97.08MiB/s ETA 00:00
[download]  82.8% of   47.60MiB at   82.44MiB/s ETA 00:00
[download]  83.9% of   47.60MiB at   60.29MiB/s ETA 00:00
[download]  86.0% of   47.60MiB at   62.80MiB/s ETA 00:00
[download]  90.2% of   47.60MiB at   57.63MiB/s ETA 00:00
[download]  98.6% of   47.60MiB at   49.69MiB/s ETA 00:00
[download] 100.0% of   47.60MiB at   50.83MiB/s ETA 00:00
[download] 100% of   47.60MiB in 00:00:02 at 16.64MiB/s  
[ExtractAudio] Destination: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/AI Snake Oil： What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference [C3TqcUEFR58].mp3
Audio downloaded: AI Snake Oil： What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference [C3TqcUEFR58].mp3

Transcribing with gpt-4o-mini-transcribe...
[GPT-4o-mini] Processing: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/AI Snake Oil： What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference [C3TqcUEFR58].mp3
[GPT-4o-mini] Using hybrid mode for accurate timestamps...
[Hybrid] Step 1: Fetching YouTube transcript with timestamps...
Error fetching transcript: 
Could not retrieve a transcript for the video https://www.youtube.com/watch?v=Intelligenc! This is most likely caused by:

The video is no longer available

If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!
[Hybrid] Error: Could not fetch YouTube transcript
[GPT-4o-mini] Hybrid mode failed, falling back to standard mode
[GPT-4o-mini] [WARNING] YouTube transcript API를 사용할 수 없어 30초 단위의 타임코드가 생성됩니다
[GPT-4o-mini] (Live 영상이거나 자막이 없는 영상일 수 있습니다)
[GPT-4o-mini] ℹ️  Using chunked timestamps for gpt-4o-mini-transcribe
[GPT-4o-mini] File is large, using chunking strategy...
[Audio] Using project temp directory: /Users/jaesolshin/Documents/GitHub/yt-trans/temp_audio
[Audio] Splitting 3408.6s audio into 114 chunks of 30s each
[Audio] Created chunk 1/114: chunk_000.mp3
[Audio] Created chunk 2/114: chunk_001.mp3
[Audio] Created chunk 3/114: chunk_002.mp3
[Audio] Created chunk 4/114: chunk_003.mp3
[Audio] Created chunk 5/114: chunk_004.mp3
[Audio] Created chunk 6/114: chunk_005.mp3
[Audio] Created chunk 7/114: chunk_006.mp3
[Audio] Created chunk 8/114: chunk_007.mp3
[Audio] Created chunk 9/114: chunk_008.mp3
[Audio] Created chunk 10/114: chunk_009.mp3
[Audio] Created chunk 11/114: chunk_010.mp3
[Audio] Created chunk 12/114: chunk_011.mp3
[Audio] Created chunk 13/114: chunk_012.mp3
[Audio] Created chunk 14/114: chunk_013.mp3
[Audio] Created chunk 15/114: chunk_014.mp3
[Audio] Created chunk 16/114: chunk_015.mp3
[Audio] Created chunk 17/114: chunk_016.mp3
[Audio] Created chunk 18/114: chunk_017.mp3
[Audio] Created chunk 19/114: chunk_018.mp3
[Audio] Created chunk 20/114: chunk_019.mp3
[Audio] Created chunk 21/114: chunk_020.mp3
[Audio] Created chunk 22/114: chunk_021.mp3
[Audio] Created chunk 23/114: chunk_022.mp3
[Audio] Created chunk 24/114: chunk_023.mp3
[Audio] Created chunk 25/114: chunk_024.mp3
[Audio] Created chunk 26/114: chunk_025.mp3
[Audio] Created chunk 27/114: chunk_026.mp3
[Audio] Created chunk 28/114: chunk_027.mp3
[Audio] Created chunk 29/114: chunk_028.mp3
[Audio] Created chunk 30/114: chunk_029.mp3
[Audio] Created chunk 31/114: chunk_030.mp3
[Audio] Created chunk 32/114: chunk_031.mp3
[Audio] Created chunk 33/114: chunk_032.mp3
[Audio] Created chunk 34/114: chunk_033.mp3
[Audio] Created chunk 35/114: chunk_034.mp3
[Audio] Created chunk 36/114: chunk_035.mp3
[Audio] Created chunk 37/114: chunk_036.mp3
[Audio] Created chunk 38/114: chunk_037.mp3
[Audio] Created chunk 39/114: chunk_038.mp3
[Audio] Created chunk 40/114: chunk_039.mp3
[Audio] Created chunk 41/114: chunk_040.mp3
[Audio] Created chunk 42/114: chunk_041.mp3
[Audio] Created chunk 43/114: chunk_042.mp3
[Audio] Created chunk 44/114: chunk_043.mp3
[Audio] Created chunk 45/114: chunk_044.mp3
[Audio] Created chunk 46/114: chunk_045.mp3
[Audio] Created chunk 47/114: chunk_046.mp3
[Audio] Created chunk 48/114: chunk_047.mp3
[Audio] Created chunk 49/114: chunk_048.mp3
[Audio] Created chunk 50/114: chunk_049.mp3
[Audio] Created chunk 51/114: chunk_050.mp3
[Audio] Created chunk 52/114: chunk_051.mp3
[Audio] Created chunk 53/114: chunk_052.mp3
[Audio] Created chunk 54/114: chunk_053.mp3
[Audio] Created chunk 55/114: chunk_054.mp3
[Audio] Created chunk 56/114: chunk_055.mp3
[Audio] Created chunk 57/114: chunk_056.mp3
[Audio] Created chunk 58/114: chunk_057.mp3
[Audio] Created chunk 59/114: chunk_058.mp3
[Audio] Created chunk 60/114: chunk_059.mp3
[Audio] Created chunk 61/114: chunk_060.mp3
[Audio] Created chunk 62/114: chunk_061.mp3
[Audio] Created chunk 63/114: chunk_062.mp3
[Audio] Created chunk 64/114: chunk_063.mp3
[Audio] Created chunk 65/114: chunk_064.mp3
[Audio] Created chunk 66/114: chunk_065.mp3
[Audio] Created chunk 67/114: chunk_066.mp3
[Audio] Created chunk 68/114: chunk_067.mp3
[Audio] Created chunk 69/114: chunk_068.mp3
[Audio] Created chunk 70/114: chunk_069.mp3
[Audio] Created chunk 71/114: chunk_070.mp3
[Audio] Created chunk 72/114: chunk_071.mp3
[Audio] Created chunk 73/114: chunk_072.mp3
[Audio] Created chunk 74/114: chunk_073.mp3
[Audio] Created chunk 75/114: chunk_074.mp3
[Audio] Created chunk 76/114: chunk_075.mp3
[Audio] Created chunk 77/114: chunk_076.mp3
[Audio] Created chunk 78/114: chunk_077.mp3
[Audio] Created chunk 79/114: chunk_078.mp3
[Audio] Created chunk 80/114: chunk_079.mp3
[Audio] Created chunk 81/114: chunk_080.mp3
[Audio] Created chunk 82/114: chunk_081.mp3
[Audio] Created chunk 83/114: chunk_082.mp3
[Audio] Created chunk 84/114: chunk_083.mp3
[Audio] Created chunk 85/114: chunk_084.mp3
[Audio] Created chunk 86/114: chunk_085.mp3
[Audio] Created chunk 87/114: chunk_086.mp3
[Audio] Created chunk 88/114: chunk_087.mp3
[Audio] Created chunk 89/114: chunk_088.mp3
[Audio] Created chunk 90/114: chunk_089.mp3
[Audio] Created chunk 91/114: chunk_090.mp3
[Audio] Created chunk 92/114: chunk_091.mp3
[Audio] Created chunk 93/114: chunk_092.mp3
[Audio] Created chunk 94/114: chunk_093.mp3
[Audio] Created chunk 95/114: chunk_094.mp3
[Audio] Created chunk 96/114: chunk_095.mp3
[Audio] Created chunk 97/114: chunk_096.mp3
[Audio] Created chunk 98/114: chunk_097.mp3
[Audio] Created chunk 99/114: chunk_098.mp3
[Audio] Created chunk 100/114: chunk_099.mp3
[Audio] Created chunk 101/114: chunk_100.mp3
[Audio] Created chunk 102/114: chunk_101.mp3
[Audio] Created chunk 103/114: chunk_102.mp3
[Audio] Created chunk 104/114: chunk_103.mp3
[Audio] Created chunk 105/114: chunk_104.mp3
[Audio] Created chunk 106/114: chunk_105.mp3
[Audio] Created chunk 107/114: chunk_106.mp3
[Audio] Created chunk 108/114: chunk_107.mp3
[Audio] Created chunk 109/114: chunk_108.mp3
[Audio] Created chunk 110/114: chunk_109.mp3
[Audio] Created chunk 111/114: chunk_110.mp3
[Audio] Created chunk 112/114: chunk_111.mp3
[Audio] Created chunk 113/114: chunk_112.mp3
[Audio] Created chunk 114/114: chunk_113.mp3
[GPT-4o-mini] Transcribing 114 chunks...

                                                                                                    
Overall: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 0.1% (0.1/114 chunks) | Speed: 22898.84 chunks/min | ETA: 0m 0s
                                                                                                    
Overall: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.2% (1.4/114 chunks) | Speed: 28.43 chunks/min | ETA: 3m 57s
[GPT-4o-mini] Chunk 5: 549 chars

                                                                                                    
Overall: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.3% (1.5/114 chunks) | Speed: 30.46 chunks/min | ETA: 3m 41s
                                                                                                    
Overall: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 2.1% (2.4/114 chunks) | Speed: 45.97 chunks/min | ETA: 2m 25s
[GPT-4o-mini] Chunk 3: 436 chars

                                                                                                    
Overall: [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 2.2% (2.5/114 chunks) | Speed: 47.88 chunks/min | ETA: 2m 19s
                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 3.0% (3.4/114 chunks) | Speed: 64.80 chunks/min | ETA: 1m 42s
[GPT-4o-mini] Chunk 1: 422 chars

                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 3.9% (4.4/114 chunks) | Speed: 76.09 chunks/min | ETA: 1m 26s
[GPT-4o-mini] Chunk 2: 437 chars

                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 3.9% (4.5/114 chunks) | Speed: 77.82 chunks/min | ETA: 1m 24s
                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 4.7% (5.4/114 chunks) | Speed: 73.34 chunks/min | ETA: 1m 28s
[GPT-4o-mini] Chunk 4: 488 chars

                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 4.8% (5.5/114 chunks) | Speed: 74.69 chunks/min | ETA: 1m 27s
                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5.6% (6.4/114 chunks) | Speed: 71.00 chunks/min | ETA: 1m 30s
[GPT-4o-mini] Chunk 6: 426 chars

                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5.7% (6.5/114 chunks) | Speed: 72.11 chunks/min | ETA: 1m 29s
                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.5% (7.4/114 chunks) | Speed: 75.76 chunks/min | ETA: 1m 24s
[GPT-4o-mini] Chunk 7: 492 chars

                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.6% (7.5/114 chunks) | Speed: 76.79 chunks/min | ETA: 1m 23s
                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 7.4% (8.4/114 chunks) | Speed: 82.30 chunks/min | ETA: 1m 16s
[GPT-4o-mini] Chunk 9: 308 chars

                                                                                                    
Overall: [██░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 7.5% (8.5/114 chunks) | Speed: 83.28 chunks/min | ETA: 1m 16s
                                                                                                    
Overall: [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 8.2% (9.4/114 chunks) | Speed: 88.86 chunks/min | ETA: 1m 10s
[GPT-4o-mini] Chunk 8: 484 chars

                                                                                                    
Overall: [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 8.3% (9.5/114 chunks) | Speed: 89.80 chunks/min | ETA: 1m 9s
                                                                                                    
Overall: [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 9.1% (10.4/114 chunks) | Speed: 76.79 chunks/min | ETA: 1m 20s
[GPT-4o-mini] Chunk 11: 493 chars

                                                                                                    
Overall: [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 9.2% (10.5/114 chunks) | Speed: 77.52 chunks/min | ETA: 1m 20s
                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10.0% (11.4/114 chunks) | Speed: 79.87 chunks/min | ETA: 1m 17s
[GPT-4o-mini] Chunk 10: 471 chars

                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10.1% (11.5/114 chunks) | Speed: 80.57 chunks/min | ETA: 1m 16s
                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10.9% (12.4/114 chunks) | Speed: 82.03 chunks/min | ETA: 1m 14s
[GPT-4o-mini] Chunk 13: 477 chars

                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 11.0% (12.5/114 chunks) | Speed: 82.69 chunks/min | ETA: 1m 13s
                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 11.8% (13.4/114 chunks) | Speed: 86.67 chunks/min | ETA: 1m 9s
[GPT-4o-mini] Chunk 12: 418 chars

                                                                                                    
Overall: [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 11.8% (13.5/114 chunks) | Speed: 87.32 chunks/min | ETA: 1m 9s
                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 12.6% (14.4/114 chunks) | Speed: 88.16 chunks/min | ETA: 1m 7s
[GPT-4o-mini] Chunk 14: 505 chars

                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 12.7% (14.5/114 chunks) | Speed: 88.77 chunks/min | ETA: 1m 7s
                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.5% (15.4/114 chunks) | Speed: 83.90 chunks/min | ETA: 1m 10s
[GPT-4o-mini] Chunk 15: 526 chars

                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.6% (15.5/114 chunks) | Speed: 84.45 chunks/min | ETA: 1m 9s
                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 14.4% (16.4/114 chunks) | Speed: 86.28 chunks/min | ETA: 1m 7s
[GPT-4o-mini] Chunk 17: 545 chars

                                                                                                    
Overall: [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 14.5% (16.5/114 chunks) | Speed: 86.80 chunks/min | ETA: 1m 7s
                                                                                                    
Overall: [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15.3% (17.4/114 chunks) | Speed: 83.85 chunks/min | ETA: 1m 9s
[GPT-4o-mini] Chunk 16: 554 chars

                                                                                                    
Overall: [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 15.4% (17.5/114 chunks) | Speed: 84.34 chunks/min | ETA: 1m 8s
                                                                                                    
Overall: [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 16.1% (18.4/114 chunks) | Speed: 88.67 chunks/min | ETA: 1m 4s
[GPT-4o-mini] Chunk 18: 587 chars

                                                                                                    
Overall: [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 17.0% (19.4/114 chunks) | Speed: 93.48 chunks/min | ETA: 1m 0s
[GPT-4o-mini] Chunk 19: 586 chars

                                                                                                    
Overall: [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 17.9% (20.4/114 chunks) | Speed: 87.53 chunks/min | ETA: 1m 4s
[GPT-4o-mini] Chunk 20: 552 chars

                                                                                                    
Overall: [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 18.0% (20.5/114 chunks) | Speed: 87.96 chunks/min | ETA: 1m 3s
                                                                                                    
Overall: [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 18.8% (21.4/114 chunks) | Speed: 91.72 chunks/min | ETA: 1m 0s
[GPT-4o-mini] Chunk 21: 508 chars

                                                                                                    
Overall: [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 19.6% (22.4/114 chunks) | Speed: 91.03 chunks/min | ETA: 1m 0s
[GPT-4o-mini] Chunk 23: 532 chars

                                                                                                    
Overall: [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 19.7% (22.5/114 chunks) | Speed: 91.44 chunks/min | ETA: 1m 0s
                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20.5% (23.4/114 chunks) | Speed: 93.96 chunks/min | ETA: 0m 57s
[GPT-4o-mini] Chunk 22: 600 chars

                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 20.6% (23.5/114 chunks) | Speed: 94.36 chunks/min | ETA: 0m 57s
                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 21.4% (24.4/114 chunks) | Speed: 96.02 chunks/min | ETA: 0m 55s
[GPT-4o-mini] Chunk 24: 473 chars

                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 21.5% (24.5/114 chunks) | Speed: 96.41 chunks/min | ETA: 0m 55s
                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 22.3% (25.4/114 chunks) | Speed: 90.53 chunks/min | ETA: 0m 58s
[GPT-4o-mini] Chunk 26: 523 chars

                                                                                                    
Overall: [████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 22.4% (25.5/114 chunks) | Speed: 90.88 chunks/min | ETA: 0m 58s
                                                                                                    
Overall: [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 23.2% (26.4/114 chunks) | Speed: 91.91 chunks/min | ETA: 0m 57s
[GPT-4o-mini] Chunk 27: 468 chars

                                                                                                    
Overall: [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 23.2% (26.5/114 chunks) | Speed: 92.26 chunks/min | ETA: 0m 56s
                                                                                                    
Overall: [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 24.0% (27.4/114 chunks) | Speed: 94.30 chunks/min | ETA: 0m 55s
[GPT-4o-mini] Chunk 25: 557 chars

                                                                                                    
Overall: [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 24.1% (27.5/114 chunks) | Speed: 94.65 chunks/min | ETA: 0m 54s
                                                                                                    
Overall: [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 24.9% (28.4/114 chunks) | Speed: 92.16 chunks/min | ETA: 0m 55s
[GPT-4o-mini] Chunk 28: 578 chars

                                                                                                    
Overall: [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25.0% (28.5/114 chunks) | Speed: 92.48 chunks/min | ETA: 0m 55s
                                                                                                    
Overall: [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25.8% (29.4/114 chunks) | Speed: 93.24 chunks/min | ETA: 0m 54s
[GPT-4o-mini] Chunk 29: 498 chars

                                                                                                    
Overall: [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25.9% (29.5/114 chunks) | Speed: 93.55 chunks/min | ETA: 0m 54s
                                                                                                    
Overall: [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 26.7% (30.4/114 chunks) | Speed: 88.19 chunks/min | ETA: 0m 56s
[GPT-4o-mini] Chunk 31: 576 chars

                                                                                                    
Overall: [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 26.8% (30.5/114 chunks) | Speed: 88.48 chunks/min | ETA: 0m 56s
                                                                                                    
Overall: [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 27.5% (31.4/114 chunks) | Speed: 89.78 chunks/min | ETA: 0m 55s
[GPT-4o-mini] Chunk 32: 509 chars

                                                                                                    
Overall: [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 27.6% (31.5/114 chunks) | Speed: 90.07 chunks/min | ETA: 0m 54s
                                                                                                    
Overall: [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 28.4% (32.4/114 chunks) | Speed: 92.57 chunks/min | ETA: 0m 52s
[GPT-4o-mini] Chunk 30: 522 chars

                                                                                                    
Overall: [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 29.3% (33.4/114 chunks) | Speed: 94.27 chunks/min | ETA: 0m 51s
[GPT-4o-mini] Chunk 33: 578 chars

                                                                                                    
Overall: [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 29.4% (33.5/114 chunks) | Speed: 94.55 chunks/min | ETA: 0m 51s
                                                                                                    
Overall: [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30.2% (34.4/114 chunks) | Speed: 90.23 chunks/min | ETA: 0m 52s
[GPT-4o-mini] Chunk 34: 508 chars

                                                                                                    
Overall: [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 30.3% (34.5/114 chunks) | Speed: 90.49 chunks/min | ETA: 0m 52s
                                                                                                    
Overall: [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 31.1% (35.4/114 chunks) | Speed: 90.68 chunks/min | ETA: 0m 52s
[GPT-4o-mini] Chunk 35: 526 chars

                                                                                                    
Overall: [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 31.1% (35.5/114 chunks) | Speed: 90.94 chunks/min | ETA: 0m 51s
                                                                                                    
Overall: [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 31.9% (36.4/114 chunks) | Speed: 93.09 chunks/min | ETA: 0m 50s
[GPT-4o-mini] Chunk 37: 483 chars

                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 32.8% (37.4/114 chunks) | Speed: 93.09 chunks/min | ETA: 0m 49s
[GPT-4o-mini] Chunk 36: 532 chars

                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 32.9% (37.5/114 chunks) | Speed: 93.33 chunks/min | ETA: 0m 49s
                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 33.7% (38.4/114 chunks) | Speed: 91.64 chunks/min | ETA: 0m 49s
[GPT-4o-mini] Chunk 38: 490 chars

                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 33.8% (38.5/114 chunks) | Speed: 91.88 chunks/min | ETA: 0m 49s
                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 34.6% (39.4/114 chunks) | Speed: 88.10 chunks/min | ETA: 0m 50s
[GPT-4o-mini] Chunk 42: 556 chars

                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 34.6% (39.5/114 chunks) | Speed: 88.32 chunks/min | ETA: 0m 50s
                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 35.4% (40.4/114 chunks) | Speed: 89.89 chunks/min | ETA: 0m 49s
[GPT-4o-mini] Chunk 41: 538 chars

                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 35.5% (40.5/114 chunks) | Speed: 90.11 chunks/min | ETA: 0m 48s
                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 36.3% (41.4/114 chunks) | Speed: 91.71 chunks/min | ETA: 0m 47s
[GPT-4o-mini] Chunk 40: 400 chars

                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 36.4% (41.5/114 chunks) | Speed: 91.93 chunks/min | ETA: 0m 47s
                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 37.2% (42.4/114 chunks) | Speed: 91.62 chunks/min | ETA: 0m 46s
[GPT-4o-mini] Chunk 43: 516 chars

                                                                                                    
Overall: [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 37.3% (42.5/114 chunks) | Speed: 91.84 chunks/min | ETA: 0m 46s
                                                                                                    
Overall: [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 38.1% (43.4/114 chunks) | Speed: 87.52 chunks/min | ETA: 0m 48s
[GPT-4o-mini] Chunk 46: 478 chars

                                                                                                    
Overall: [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 38.2% (43.5/114 chunks) | Speed: 87.72 chunks/min | ETA: 0m 48s
                                                                                                    
Overall: [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 38.9% (44.4/114 chunks) | Speed: 87.35 chunks/min | ETA: 0m 47s
[GPT-4o-mini] Chunk 47: 479 chars

                                                                                                    
Overall: [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 39.0% (44.5/114 chunks) | Speed: 87.55 chunks/min | ETA: 0m 47s
                                                                                                    
Overall: [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 39.8% (45.4/114 chunks) | Speed: 89.20 chunks/min | ETA: 0m 46s
[GPT-4o-mini] Chunk 44: 518 chars

                                                                                                    
Overall: [████████████████░░░░░░░░░░░░░░░░░░░░░░░░] 40.7% (46.4/114 chunks) | Speed: 89.78 chunks/min | ETA: 0m 45s
[GPT-4o-mini] Chunk 45: 552 chars

                                                                                                    
Overall: [████████████████░░░░░░░░░░░░░░░░░░░░░░░░] 40.8% (46.5/114 chunks) | Speed: 89.97 chunks/min | ETA: 0m 45s
                                                                                                    
Overall: [████████████████░░░░░░░░░░░░░░░░░░░░░░░░] 41.6% (47.4/114 chunks) | Speed: 91.34 chunks/min | ETA: 0m 43s
[GPT-4o-mini] Chunk 39: 485 chars

                                                                                                    
Overall: [████████████████░░░░░░░░░░░░░░░░░░░░░░░░] 41.7% (47.5/114 chunks) | Speed: 91.53 chunks/min | ETA: 0m 43s
                                                                                                    
Overall: [████████████████░░░░░░░░░░░░░░░░░░░░░░░░] 42.5% (48.4/114 chunks) | Speed: 88.41 chunks/min | ETA: 0m 44s
[GPT-4o-mini] Chunk 48: 557 chars

                                                                                                    
Overall: [█████████████████░░░░░░░░░░░░░░░░░░░░░░░] 42.5% (48.5/114 chunks) | Speed: 88.60 chunks/min | ETA: 0m 44s
                                                                                                    
Overall: [█████████████████░░░░░░░░░░░░░░░░░░░░░░░] 43.3% (49.4/114 chunks) | Speed: 89.99 chunks/min | ETA: 0m 43s
[GPT-4o-mini] Chunk 50: 428 chars

                                                                                                    
Overall: [█████████████████░░░░░░░░░░░░░░░░░░░░░░░] 44.2% (50.4/114 chunks) | Speed: 91.70 chunks/min | ETA: 0m 41s
[GPT-4o-mini] Chunk 49: 490 chars

                                                                                                    
Overall: [█████████████████░░░░░░░░░░░░░░░░░░░░░░░] 44.3% (50.5/114 chunks) | Speed: 91.88 chunks/min | ETA: 0m 41s
                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 45.1% (51.4/114 chunks) | Speed: 91.72 chunks/min | ETA: 0m 40s
[GPT-4o-mini] Chunk 52: 503 chars

                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 45.2% (51.5/114 chunks) | Speed: 91.90 chunks/min | ETA: 0m 40s
                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 46.0% (52.4/114 chunks) | Speed: 91.67 chunks/min | ETA: 0m 40s
[GPT-4o-mini] Chunk 51: 484 chars

                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 46.1% (52.5/114 chunks) | Speed: 91.84 chunks/min | ETA: 0m 40s
                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 46.8% (53.4/114 chunks) | Speed: 90.27 chunks/min | ETA: 0m 40s
[GPT-4o-mini] Chunk 55: 355 chars

                                                                                                    
Overall: [██████████████████░░░░░░░░░░░░░░░░░░░░░░] 46.9% (53.5/114 chunks) | Speed: 90.44 chunks/min | ETA: 0m 40s
                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 47.7% (54.4/114 chunks) | Speed: 90.71 chunks/min | ETA: 0m 39s
[GPT-4o-mini] Chunk 53: 584 chars

                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 47.8% (54.5/114 chunks) | Speed: 90.88 chunks/min | ETA: 0m 39s
                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 48.6% (55.4/114 chunks) | Speed: 91.17 chunks/min | ETA: 0m 38s
[GPT-4o-mini] Chunk 54: 376 chars

                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 48.7% (55.5/114 chunks) | Speed: 91.33 chunks/min | ETA: 0m 38s
                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 49.5% (56.4/114 chunks) | Speed: 92.53 chunks/min | ETA: 0m 37s
[GPT-4o-mini] Chunk 56: 356 chars

                                                                                                    
Overall: [███████████████████░░░░░░░░░░░░░░░░░░░░░] 49.6% (56.5/114 chunks) | Speed: 92.69 chunks/min | ETA: 0m 37s
                                                                                                    
Overall: [████████████████████░░░░░░░░░░░░░░░░░░░░] 50.4% (57.4/114 chunks) | Speed: 93.75 chunks/min | ETA: 0m 36s
[GPT-4o-mini] Chunk 57: 488 chars

                                                                                                    
Overall: [████████████████████░░░░░░░░░░░░░░░░░░░░] 50.4% (57.5/114 chunks) | Speed: 93.91 chunks/min | ETA: 0m 36s
                                                                                                    
Overall: [████████████████████░░░░░░░░░░░░░░░░░░░░] 51.2% (58.4/114 chunks) | Speed: 91.01 chunks/min | ETA: 0m 36s
[GPT-4o-mini] Chunk 58: 422 chars

                                                                                                    
Overall: [████████████████████░░░░░░░░░░░░░░░░░░░░] 51.3% (58.5/114 chunks) | Speed: 91.17 chunks/min | ETA: 0m 36s
                                                                                                    
Overall: [████████████████████░░░░░░░░░░░░░░░░░░░░] 52.1% (59.4/114 chunks) | Speed: 92.50 chunks/min | ETA: 0m 35s
[GPT-4o-mini] Chunk 59: 540 chars

                                                                                                    
Overall: [█████████████████████░░░░░░░░░░░░░░░░░░░] 53.0% (60.4/114 chunks) | Speed: 92.46 chunks/min | ETA: 0m 34s
[GPT-4o-mini] Chunk 61: 526 chars

                                                                                                    
Overall: [█████████████████████░░░░░░░░░░░░░░░░░░░] 53.1% (60.5/114 chunks) | Speed: 92.61 chunks/min | ETA: 0m 34s
                                                                                                    
Overall: [█████████████████████░░░░░░░░░░░░░░░░░░░] 53.9% (61.4/114 chunks) | Speed: 93.91 chunks/min | ETA: 0m 33s
[GPT-4o-mini] Chunk 60: 523 chars

                                                                                                    
Overall: [█████████████████████░░░░░░░░░░░░░░░░░░░] 54.7% (62.4/114 chunks) | Speed: 94.54 chunks/min | ETA: 0m 32s
[GPT-4o-mini] Chunk 62: 440 chars

                                                                                                    
Overall: [█████████████████████░░░░░░░░░░░░░░░░░░░] 54.8% (62.5/114 chunks) | Speed: 94.69 chunks/min | ETA: 0m 32s
                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 55.6% (63.4/114 chunks) | Speed: 92.99 chunks/min | ETA: 0m 32s
[GPT-4o-mini] Chunk 64: 454 chars

                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 55.7% (63.5/114 chunks) | Speed: 93.13 chunks/min | ETA: 0m 32s
                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 56.5% (64.4/114 chunks) | Speed: 94.41 chunks/min | ETA: 0m 31s
[GPT-4o-mini] Chunk 63: 387 chars

                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 57.4% (65.4/114 chunks) | Speed: 93.76 chunks/min | ETA: 0m 31s
[GPT-4o-mini] Chunk 66: 572 chars

                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 57.5% (65.5/114 chunks) | Speed: 93.90 chunks/min | ETA: 0m 30s
                                                                                                    
Overall: [███████████████████████░░░░░░░░░░░░░░░░░] 58.2% (66.4/114 chunks) | Speed: 92.51 chunks/min | ETA: 0m 30s
[GPT-4o-mini] Chunk 65: 498 chars

                                                                                                    
Overall: [███████████████████████░░░░░░░░░░░░░░░░░] 58.3% (66.5/114 chunks) | Speed: 92.65 chunks/min | ETA: 0m 30s
                                                                                                    
Overall: [███████████████████████░░░░░░░░░░░░░░░░░] 59.1% (67.4/114 chunks) | Speed: 93.60 chunks/min | ETA: 0m 29s
[GPT-4o-mini] Chunk 67: 605 chars

                                                                                                    
Overall: [███████████████████████░░░░░░░░░░░░░░░░░] 59.2% (67.5/114 chunks) | Speed: 93.74 chunks/min | ETA: 0m 29s
                                                                                                    
Overall: [███████████████████████░░░░░░░░░░░░░░░░░] 60.0% (68.4/114 chunks) | Speed: 94.73 chunks/min | ETA: 0m 28s
[GPT-4o-mini] Chunk 69: 434 chars

                                                                                                    
Overall: [████████████████████████░░░░░░░░░░░░░░░░] 60.1% (68.5/114 chunks) | Speed: 94.87 chunks/min | ETA: 0m 28s
                                                                                                    
Overall: [████████████████████████░░░░░░░░░░░░░░░░] 60.9% (69.4/114 chunks) | Speed: 95.09 chunks/min | ETA: 0m 28s
[GPT-4o-mini] Chunk 68: 546 chars

                                                                                                    
Overall: [████████████████████████░░░░░░░░░░░░░░░░] 61.0% (69.5/114 chunks) | Speed: 95.22 chunks/min | ETA: 0m 28s
                                                                                                    
Overall: [████████████████████████░░░░░░░░░░░░░░░░] 61.8% (70.4/114 chunks) | Speed: 95.37 chunks/min | ETA: 0m 27s
[GPT-4o-mini] Chunk 70: 492 chars

                                                                                                    
Overall: [████████████████████████░░░░░░░░░░░░░░░░] 61.8% (70.5/114 chunks) | Speed: 95.50 chunks/min | ETA: 0m 27s
                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 62.6% (71.4/114 chunks) | Speed: 93.25 chunks/min | ETA: 0m 27s
[GPT-4o-mini] Chunk 73: 612 chars

                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 62.7% (71.5/114 chunks) | Speed: 93.38 chunks/min | ETA: 0m 27s
                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 63.5% (72.4/114 chunks) | Speed: 93.93 chunks/min | ETA: 0m 26s
[GPT-4o-mini] Chunk 71: 471 chars

                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 63.6% (72.5/114 chunks) | Speed: 94.06 chunks/min | ETA: 0m 26s
                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 64.4% (73.4/114 chunks) | Speed: 94.71 chunks/min | ETA: 0m 25s
[GPT-4o-mini] Chunk 72: 562 chars

                                                                                                    
Overall: [█████████████████████████░░░░░░░░░░░░░░░] 64.5% (73.5/114 chunks) | Speed: 94.84 chunks/min | ETA: 0m 25s
                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 65.3% (74.4/114 chunks) | Speed: 95.44 chunks/min | ETA: 0m 24s
[GPT-4o-mini] Chunk 74: 467 chars

                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 65.4% (74.5/114 chunks) | Speed: 95.57 chunks/min | ETA: 0m 24s
                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 66.1% (75.4/114 chunks) | Speed: 94.72 chunks/min | ETA: 0m 24s
[GPT-4o-mini] Chunk 75: 489 chars

                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 66.2% (75.5/114 chunks) | Speed: 94.84 chunks/min | ETA: 0m 24s
                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 67.0% (76.4/114 chunks) | Speed: 93.93 chunks/min | ETA: 0m 24s
[GPT-4o-mini] Chunk 76: 485 chars

                                                                                                    
Overall: [██████████████████████████░░░░░░░░░░░░░░] 67.1% (76.5/114 chunks) | Speed: 94.05 chunks/min | ETA: 0m 23s
                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 67.9% (77.4/114 chunks) | Speed: 94.17 chunks/min | ETA: 0m 23s
[GPT-4o-mini] Chunk 78: 473 chars

                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 68.0% (77.5/114 chunks) | Speed: 94.29 chunks/min | ETA: 0m 23s
                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 68.8% (78.4/114 chunks) | Speed: 94.86 chunks/min | ETA: 0m 22s
[GPT-4o-mini] Chunk 77: 620 chars

                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 68.9% (78.5/114 chunks) | Speed: 94.98 chunks/min | ETA: 0m 22s
                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 69.6% (79.4/114 chunks) | Speed: 95.60 chunks/min | ETA: 0m 21s
[GPT-4o-mini] Chunk 79: 518 chars

                                                                                                    
Overall: [███████████████████████████░░░░░░░░░░░░░] 69.7% (79.5/114 chunks) | Speed: 95.72 chunks/min | ETA: 0m 21s
                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 70.5% (80.4/114 chunks) | Speed: 95.83 chunks/min | ETA: 0m 21s
[GPT-4o-mini] Chunk 80: 498 chars

                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 70.6% (80.5/114 chunks) | Speed: 95.95 chunks/min | ETA: 0m 20s
                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 71.4% (81.4/114 chunks) | Speed: 94.58 chunks/min | ETA: 0m 20s
[GPT-4o-mini] Chunk 81: 487 chars

                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 71.5% (81.5/114 chunks) | Speed: 94.69 chunks/min | ETA: 0m 20s
                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 72.3% (82.4/114 chunks) | Speed: 94.97 chunks/min | ETA: 0m 19s
[GPT-4o-mini] Chunk 83: 490 chars

                                                                                                    
Overall: [████████████████████████████░░░░░░░░░░░░] 72.4% (82.5/114 chunks) | Speed: 95.09 chunks/min | ETA: 0m 19s
                                                                                                    
Overall: [█████████████████████████████░░░░░░░░░░░] 73.2% (83.4/114 chunks) | Speed: 94.63 chunks/min | ETA: 0m 19s
[GPT-4o-mini] Chunk 82: 342 chars

                                                                                                    
Overall: [█████████████████████████████░░░░░░░░░░░] 73.2% (83.5/114 chunks) | Speed: 94.74 chunks/min | ETA: 0m 19s
                                                                                                    
Overall: [█████████████████████████████░░░░░░░░░░░] 74.0% (84.4/114 chunks) | Speed: 95.73 chunks/min | ETA: 0m 18s
[GPT-4o-mini] Chunk 85: 492 chars

                                                                                                    
Overall: [█████████████████████████████░░░░░░░░░░░] 74.9% (85.4/114 chunks) | Speed: 96.82 chunks/min | ETA: 0m 17s
[GPT-4o-mini] Chunk 84: 494 chars

                                                                                                    
Overall: [██████████████████████████████░░░░░░░░░░] 75.8% (86.4/114 chunks) | Speed: 95.24 chunks/min | ETA: 0m 17s
[GPT-4o-mini] Chunk 86: 557 chars

                                                                                                    
Overall: [██████████████████████████████░░░░░░░░░░] 75.9% (86.5/114 chunks) | Speed: 95.35 chunks/min | ETA: 0m 17s
                                                                                                    
Overall: [██████████████████████████████░░░░░░░░░░] 76.7% (87.4/114 chunks) | Speed: 95.61 chunks/min | ETA: 0m 16s
[GPT-4o-mini] Chunk 87: 532 chars

                                                                                                    
Overall: [██████████████████████████████░░░░░░░░░░] 76.8% (87.5/114 chunks) | Speed: 95.72 chunks/min | ETA: 0m 16s
                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 77.5% (88.4/114 chunks) | Speed: 95.92 chunks/min | ETA: 0m 16s
[GPT-4o-mini] Chunk 89: 368 chars

                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 77.6% (88.5/114 chunks) | Speed: 96.03 chunks/min | ETA: 0m 15s
                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 78.4% (89.4/114 chunks) | Speed: 95.65 chunks/min | ETA: 0m 15s
[GPT-4o-mini] Chunk 88: 468 chars

                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 78.5% (89.5/114 chunks) | Speed: 95.76 chunks/min | ETA: 0m 15s
                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 79.3% (90.4/114 chunks) | Speed: 96.15 chunks/min | ETA: 0m 14s
[GPT-4o-mini] Chunk 90: 344 chars

                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 79.4% (90.5/114 chunks) | Speed: 96.26 chunks/min | ETA: 0m 14s
                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 80.2% (91.4/114 chunks) | Speed: 96.78 chunks/min | ETA: 0m 14s
[GPT-4o-mini] Chunk 91: 529 chars

                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 80.3% (91.5/114 chunks) | Speed: 96.89 chunks/min | ETA: 0m 13s
                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 81.1% (92.4/114 chunks) | Speed: 96.32 chunks/min | ETA: 0m 13s
[GPT-4o-mini] Chunk 93: 393 chars

                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 81.1% (92.5/114 chunks) | Speed: 96.43 chunks/min | ETA: 0m 13s
                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 81.9% (93.4/114 chunks) | Speed: 96.81 chunks/min | ETA: 0m 12s
[GPT-4o-mini] Chunk 92: 500 chars

                                                                                                    
Overall: [████████████████████████████████░░░░░░░░] 82.0% (93.5/114 chunks) | Speed: 96.91 chunks/min | ETA: 0m 12s
                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 82.8% (94.4/114 chunks) | Speed: 96.12 chunks/min | ETA: 0m 12s
[GPT-4o-mini] Chunk 96: 591 chars

                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 82.9% (94.5/114 chunks) | Speed: 96.23 chunks/min | ETA: 0m 12s
                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 83.7% (95.4/114 chunks) | Speed: 96.86 chunks/min | ETA: 0m 11s
[GPT-4o-mini] Chunk 94: 486 chars

                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 83.8% (95.5/114 chunks) | Speed: 96.97 chunks/min | ETA: 0m 11s
                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 84.6% (96.4/114 chunks) | Speed: 97.46 chunks/min | ETA: 0m 10s
[GPT-4o-mini] Chunk 95: 448 chars

                                                                                                    
Overall: [█████████████████████████████████░░░░░░░] 84.6% (96.5/114 chunks) | Speed: 97.56 chunks/min | ETA: 0m 10s
                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 85.4% (97.4/114 chunks) | Speed: 97.45 chunks/min | ETA: 0m 10s
[GPT-4o-mini] Chunk 97: 532 chars

                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 85.5% (97.5/114 chunks) | Speed: 97.55 chunks/min | ETA: 0m 10s
                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 86.3% (98.4/114 chunks) | Speed: 96.48 chunks/min | ETA: 0m 9s
[GPT-4o-mini] Chunk 98: 550 chars

                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 86.4% (98.5/114 chunks) | Speed: 96.58 chunks/min | ETA: 0m 9s
                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 87.2% (99.4/114 chunks) | Speed: 96.46 chunks/min | ETA: 0m 9s
[GPT-4o-mini] Chunk 99: 632 chars

                                                                                                    
Overall: [██████████████████████████████████░░░░░░] 87.3% (99.5/114 chunks) | Speed: 96.56 chunks/min | ETA: 0m 9s
                                                                                                    
Overall: [███████████████████████████████████░░░░░] 88.1% (100.4/114 chunks) | Speed: 97.13 chunks/min | ETA: 0m 8s
[GPT-4o-mini] Chunk 101: 515 chars

                                                                                                    
Overall: [███████████████████████████████████░░░░░] 88.2% (100.5/114 chunks) | Speed: 97.23 chunks/min | ETA: 0m 8s
                                                                                                    
Overall: [███████████████████████████████████░░░░░] 88.9% (101.4/114 chunks) | Speed: 97.16 chunks/min | ETA: 0m 7s
[GPT-4o-mini] Chunk 100: 241 chars

                                                                                                    
Overall: [███████████████████████████████████░░░░░] 89.0% (101.5/114 chunks) | Speed: 97.26 chunks/min | ETA: 0m 7s
                                                                                                    
Overall: [███████████████████████████████████░░░░░] 89.8% (102.4/114 chunks) | Speed: 98.02 chunks/min | ETA: 0m 7s
[GPT-4o-mini] Chunk 102: 576 chars

                                                                                                    
Overall: [████████████████████████████████████░░░░] 90.7% (103.4/114 chunks) | Speed: 97.32 chunks/min | ETA: 0m 6s
[GPT-4o-mini] Chunk 103: 405 chars

                                                                                                    
Overall: [████████████████████████████████████░░░░] 90.8% (103.5/114 chunks) | Speed: 97.42 chunks/min | ETA: 0m 6s
                                                                                                    
Overall: [████████████████████████████████████░░░░] 91.6% (104.4/114 chunks) | Speed: 97.68 chunks/min | ETA: 0m 5s
[GPT-4o-mini] Chunk 104: 509 chars

                                                                                                    
Overall: [████████████████████████████████████░░░░] 91.7% (104.5/114 chunks) | Speed: 97.77 chunks/min | ETA: 0m 5s
                                                                                                    
Overall: [████████████████████████████████████░░░░] 92.5% (105.4/114 chunks) | Speed: 97.83 chunks/min | ETA: 0m 5s
[GPT-4o-mini] Chunk 105: 286 chars

                                                                                                    
Overall: [█████████████████████████████████████░░░] 92.5% (105.5/114 chunks) | Speed: 97.93 chunks/min | ETA: 0m 5s
                                                                                                    
Overall: [█████████████████████████████████████░░░] 93.3% (106.4/114 chunks) | Speed: 98.54 chunks/min | ETA: 0m 4s
[GPT-4o-mini] Chunk 106: 340 chars

                                                                                                    
Overall: [█████████████████████████████████████░░░] 93.4% (106.5/114 chunks) | Speed: 98.64 chunks/min | ETA: 0m 4s
                                                                                                    
Overall: [█████████████████████████████████████░░░] 94.2% (107.4/114 chunks) | Speed: 98.86 chunks/min | ETA: 0m 4s
[GPT-4o-mini] Chunk 107: 516 chars

                                                                                                    
Overall: [█████████████████████████████████████░░░] 94.3% (107.5/114 chunks) | Speed: 98.96 chunks/min | ETA: 0m 3s
                                                                                                    
Overall: [██████████████████████████████████████░░] 95.1% (108.4/114 chunks) | Speed: 97.48 chunks/min | ETA: 0m 3s
[GPT-4o-mini] Chunk 110: 266 chars

                                                                                                    
Overall: [██████████████████████████████████████░░] 95.2% (108.5/114 chunks) | Speed: 97.57 chunks/min | ETA: 0m 3s
                                                                                                    
Overall: [██████████████████████████████████████░░] 96.0% (109.4/114 chunks) | Speed: 97.92 chunks/min | ETA: 0m 2s
[GPT-4o-mini] Chunk 109: 424 chars

                                                                                                    
Overall: [██████████████████████████████████████░░] 96.1% (109.5/114 chunks) | Speed: 98.01 chunks/min | ETA: 0m 2s
                                                                                                    
Overall: [██████████████████████████████████████░░] 96.8% (110.4/114 chunks) | Speed: 98.17 chunks/min | ETA: 0m 2s
[GPT-4o-mini] Chunk 108: 372 chars

                                                                                                    
Overall: [███████████████████████████████████████░] 97.6% (111.3/114 chunks) | Speed: 98.96 chunks/min | ETA: 0m 1s
[GPT-4o-mini] Chunk 111: 515 chars

                                                                                                    
Overall: [███████████████████████████████████████░] 98.4% (112.2/114 chunks) | Speed: 99.54 chunks/min | ETA: 0m 1s
[GPT-4o-mini] Chunk 112: 557 chars

                                                                                                    
Overall: [███████████████████████████████████████░] 99.2% (113.1/114 chunks) | Speed: 98.38 chunks/min | ETA: 0m 0s
[GPT-4o-mini] Chunk 114: 148 chars

                                                                                                    
Overall: [████████████████████████████████████████] 100.0% (114.0/114 chunks) | Speed: 98.26 chunks/min | ETA: calculating...
[GPT-4o-mini] Chunk 113: 523 chars

[WorkerPool] Completed 114 chunks in 1m 9s
[WorkerPool] Worker 13707014144: Processed 24 chunks, avg time: 2.8s
[WorkerPool] Worker 6141177856: Processed 24 chunks, avg time: 2.9s
[WorkerPool] Worker 6107525120: Processed 20 chunks, avg time: 3.4s
[WorkerPool] Worker 6124351488: Processed 22 chunks, avg time: 3.1s
[WorkerPool] Worker 6158004224: Processed 24 chunks, avg time: 2.9s
[GPT-4o-mini] Completed: 114/114 chunks
[GPT-4o-mini] Streaming transcription...
------------------------------------------------------------
[00:00] Maybe we should get started, right? Hi, everyone. It's
a pleasure to welcome you all to tonight's talk with
Professor Arvind Narayanan. The Schwarzman College of Computing is honored
to co-host this event with MIT's Shaping the Future of
Work initiative. We're excited to have this unique convergence of
minds and missions at the intersection of technology, society, and
future of work. We're honored to be joined [00:30] I'm
Professor Arvind Narayanan from Princeton, also the co-author of the
book AI Snake Oil. At such a critical time when
there's so much debate and discussion around the promise and
peril of AI, with many people focusing on existential risk,
Arvind and Sayash's book brings a breath of fresh air
and provides a balanced perspective on how we can navigate
the hype and reality of AI. I personally recommend this
book to everyone. [01:00] Arvind in the book draws a
parallel, a very effective parallel with snake oil, whose sellers
promise miracle cures with false pretenses, sometimes ineffective but harmless,
but in other cases harms extending to loss of health
or life. Very similar to AI. AI snake oil is
AI that does not and cannot work, and the goal
of the book is to identify AI snake oil and
to distinguish it from places where AI can work very
effectively. [01:30] especially in high-stakes settings such as hiring, healthcare,
and justice. I'm thrilled to represent the Schwarzman College of
Computing as the Deputy Dean of Academics, and our Dean,
Dan Huttenlocher, is also here with us tonight. And it's
truly a pleasure to be here with the dynamic leaders
of the Shaping the Future of Work initiative, Daron Acemoğlu
and David Autor. Simon's not here. And also an effective
leader, dynamic leader, Simon Johnson, who couldn't join us today.
[02:00] The future of work brings inevitable space lens to
economic and policy impacts of automation, and the Schwarzman College
is reimagining how we do research and teach computing with
social implications at our core. What unites these efforts and
why we're so excited to have Arvind here tonight is
a shared commitment to clarity, rigor, and technical expertise in
how AI technology is developed and deployed. Tonight's presentation and
conversation promises to enlighten us, make us think about these
important issues, and with that, please... [02:30] Join me in
welcoming Professor Daron Acemoglu from the Department of Economics, Institute
Professor and Faculty Co-Director of Shaping the Future of Work
Initiative. Thank you, Asu. I don't need that. I have
the lapel mic. Thank you. Thank you very much. Thank
you, Asu, and thank you for everybody for being here.
This is a great event, and I'm delighted that people
recognize it as a great event and filled it here.
[03:00] I want to say just two more words about
the initiative for shaping the future of work, which is
co-led by myself, David Autor, and Simon Johnson, who unfortunately
couldn't be here. And part of the reason why I
want to say that is because I want to emphasize
how synergistic Arvind's agenda is to what we want to
do. We've launched this initiative because we're worried about the
future of work, the future of inequality, the future of
productivity in the age of digital technologies [03:30] AI, and
part of the reason we are concerned is precisely about
how AI and other technologies are going to be used.
And the perspective, as the word shaping suggests, is one
in which we argue that the future of these technologies
is not given, is not preordained, but different technologies have
different consequences and we want to understand those consequences and
we want to steer technology via a variety of channels,
mostly coming from the academic research we're doing. [04:00] and
our affiliates are doing towards the more socially beneficial directions.
And I think I cannot imagine somebody better than Arvind
to actually sort of give much greater depth and breadth
to this because Arvind is a professor of computer science
at Princeton and the director of the Center for... [04:30]
and policy is bringing, even without the book, a unique
perspective, great technical expertise, but a very clear-eyed, deep understanding
of many applications of AI. And that is exactly the
space where we need to be, not excessive optimism, not
excessive pessimism, but understand what are the things that AI
can do productively, what are the things it cannot do
at the moment, perhaps never, and what are the things
that it can do but are not going to be
great. [05:00] So Arvind's book, AI Snake Oil, which you're
going to hear about, is full of amazing insights ranging
from predictive AI to generative AI, large language models to
social media to machine learning and the mistakes you can
make with machine learning. I think we're going to get
a glimpse of many of these excellent points and hopefully
a lot of food for thought for everybody. Arvind's going
to speak for 20-25 minutes and then we're going to
have a little bit of a conversation for 15 [05:30]
and then we're going to open it up for Q&A.
So please give a warm welcome to Arvind and we're
really delighted to have him here. Hello, everybody. Thank you,
Darun and Asif, for such kind words. It's really my
pleasure to be here today. And I really mean it
because the origin story of this book is actually right
here at MIT. So let me tell you how that
happened. This was way back in 2019 when I kept
seeing [06:00] hiring automation software. And the pitch of these
AI companies to HR departments was, look, you're getting hundreds
of applications, maybe a thousand for each open position. You
can't possibly manually review all of them, so use our
AI software and ask your candidates to record a video
of themselves speaking for like 30 seconds, not even about
their job qualifications, but about their hobbies or whatever. And
this is from the promotional materials of an actual... [06:30]
and the pitch was that our AI will analyze that
video and look at the body language, speech patterns, things
like that, in order to be able to figure out
their personality and their suitability for your particular job. And
you can see here the software has characterized this person
on multiple dimensions of personality. That's only one of five
tabs. And on the top right, they have been characterized
as a change agent, and their score is 8.982 digits
of precision. That's how you know it's AI. [07:00] And
it didn't seem to me that there is any known
way by which this could possibly work. And sure enough,
now six years later, none of these companies have released
a shred of evidence that this can actually predict someone's
job performance. And in the few instances that journalists have
been able to use creative methods to try to see
if these techniques work or not, here's the kind of
thing that they have found. So here was an investigative
journalist who uploaded a video, two copies of a video,
and in one case [07:30] digitally added a bookshelf in
the background, and they also tried changing in another experiment
glasses versus no glasses, radically different scores. Right? So I
didn't have this evidence back then, but this is what
I suspected, and coincidentally at that time I was invited
to give a talk here, and I gave a talk
called How to Recognize AI Snake Oil, and I said,
look, there are many kinds of AI. Some things like
generative AI, which wasn't called generative AI back then, those
are making rapid progress. They work well, but there are
also [08:00] claims being made like this. I called it
an elaborate random number generator. And people seemed to like
that talk. So I put the slides online the next
day. I thought 20 of my colleagues would look at
it. But in fact, the slides went viral, which I
didn't know was a thing that could happen with academic
work. And I realized it wasn't because I had said
something profound, but because we suspect that a lot of
the AI-related claims being made are not necessarily true. But,
you know, these are being made by a trillion-dollar company.
[08:30] and supposed geniuses, so we don't feel like we
necessarily have the confidence to call it out. And so
when I was able to say, look, I'm a computer
science professor, I study AI, I build AI, and I
can tell you that some of these claims aren't backed
by evidence, that seemed to resonate with a lot of
people. And within a couple of days, I had like
30 or 40 invitations to turn that talk into an
article or even a book. I really wanted to write
that book, but I didn't feel ready because I knew
that there was a lot of research to be done
in presenting a more rigorous framework [09:00] to understand when
AI works and when it doesn't. And so that's when
Saiash Kapoor joined me as a graduate student. So we
did about five years of research, and the book is
a summary and a synthesis of that research, some of
which we've also published in the form of a series
of papers leading up to that. So let me just
take the next 15 minutes or so to give you
some of the main ideas from the book. The starting
point of the book is to recognize that AI is
not one single technology. It's an umbrella term for a
set of technologies that are only loosely related to each
other. [09:30] This is ChatGPT, I don't need to tell
you what it is. But on the other hand, technology
that banks might use in order to classify someone's credit
risk is also called AI. There's a reason they're both
called AI. They're both forms of learning from data. But
in all the ways that matter, in how the technology
works, what the application is, and most importantly, how it
might fail and what the consequences are, these two things
couldn't be more different from each other. So the thing
on the right is an example of what we call
predictive AI. [10:00] And what all predictive AI applications have
in common is a certain logic for decision-making. It's ways
of making decisions about people, often very consequential decisions, based
on a prediction of what they will do in the
future or what will happen to them in the future.
And that decision is made using machine learning based on
data from past similar people. So this is used in
hiring and there the logic is who will do well
at a job. It's used in lending, there the logic
is who might pay back [10:30] Alone or not, it's
used in criminal justice, and there the logic is, who
might commit a crime or not commit a crime. It's
used in healthcare, it's used in education, ever-expanding set of
domains. And predictive AI is something we're very dubious about,
and I'll come back to that in a second. And
then of course there's generative AI. In addition to generating
text, there's an ever-expanding variety of things that it can
do. We also talk a lot in the book about
social media algorithms and what are some of the societal
scale risks that can arise out of that as opposed
to discrete risks. [11:00] to particular individuals. And we talk
a little bit about self-driving cars and robotics, which I
will come back to in a few minutes. So why
are we so skeptical about predictive AI? If we look
at the criminal justice example, for instance, in the majority
of jurisdictions today, when someone is arrested, when the judge
faces a decision, you know, there's months or maybe years
until their trial, should that person spend that time in
jail or should they be free to go? Or should
there be an ankle monitor or any number of [11:30]
options for release. That decision is made or guided by
an algorithmic system and automated decision-making system, or at least
decision recommendation system. It's a statistical learning system. You could
call it AI. It's something that falls under the umbrella
of what we call predictive AI. And the problems with
this have been known for a long time. In 2016,
there was this well-known investigation by ProPublica called Machine Bias,
where they did a framework [12:00] information act requests, these
companies are notoriously secretive. They managed to get a lot
of data and they showed that the false positive rate
for the particular algorithm that they studied was twice as
high for Black defendants as it was for white defendants.
And so we've known about these problems with racial bias,
but when I looked at that study, there was one
thread in it that I felt didn't get picked up
nearly enough, which is that the predictive accuracy of these
methods is not really that high. So if you know
about how accuracy... [12:30] measured in machine learning, AUC is
often used, area under the curve, and the best numbers
that you can get here are less than 70%, and
50% is random guessing, right? So we're making decisions about
someone's freedom based on something that's only slightly more accurate
than the flip of a coin. And the mass majority
of people who are predicted to be at high risk
did not in fact go on to commit another crime.
So we felt that, you know, how is it ethical
to use this for anybody, whether it's a black defendant?
[13:00] So that is one of the main points we
make in the book and also in papers leading up
to that, that it's hard to predict the future, and
it's not a matter of a limitation of the technology.
We just don't know who's going to commit a crime
in the future. And so we shouldn't so easily accept
this idea of pre-crime, of determining someone's fate based on
a prediction of a crime they will commit in the
future as opposed to a determination of guilt. OK, so
let's [13:30] Let's talk about generative AI. There's a lot
more to say about predictive AI, but maybe we can
save that for the conversation and for the Q&A. Generative
AI, of course, in addition to text, it can generate
any one of a number of things. And look, there
are limitations, there's a lot of hype, and I'll talk
about some of the downsides in a second. But we're
also very clear in the book that generative AI is
useful to basically every knowledge worker, anyone who thinks for
a living. And I'm sure we'll talk about the labor
implications. But I also wanted to emphasize [14:00] that a
big aspect of it is that it's technology a lot
of the time that's just very fun to use. And
I just wanted to keep that in the conversation because
that is often easily forgotten when we're talking about these
serious aspects of AI. And in my own personal use
of AI, I certainly use it for my research, but
quite a bit in my personal life as well. I
have two young kids and I often find myself using
AI in ways that really enrich our relationship when I'm
spending time with my kids. [14:30] The other day, for
instance, I was teaching my daughter fractions. It's hard for
a kid to understand the idea of fractions, so I
pulled out an AI app on my phone. And these
days you can produce a little app that's created on
the spot by AI based on a text description of
what you want the app to do. So I asked
the AI agent to create an app to visualize fractions,
and it made this little game. It's a little slider,
and it generates a random fraction and asks the child
to try to guess where it goes on the line.
[15:00] and once they guess it will check that guess
and it will divide the line into many parts, visualize
what one-third looks like, give a score and keep score,
and you know, keep generating new fractions. So we played
with this for like 15 minutes and it really helped
her. I've done this with all kinds of things, generating
random clock faces is a way to teach her to
tell time, etc. And what's really cool about this is
that you make this app once, you play with it,
you know, my child doesn't have a huge attention span,
it's useful for 15 minutes and then it's done. [15:30]
throw it away. And that's amazing. You couldn't have imagined
doing this a couple of years ago because it would
have taken at a minimum several hours to create an
app. Okay, so with that said, we are also critical
in the book about the generative AI industry's irresponsible release
practices. And there are, of course, many harmful consequences of
this. And as we say in the book, it's like
everyone in the world has been simultaneously given the equivalent
of a free buzzsaw. There are AI-generated [16:00] books on
Amazon by people just trying to make a buck. In
some cases, you know, it's just an annoyance. Maybe you
lost 99 cents, which is often what these things are
sold for because you unknowingly bought an AI-generated book. But
in some cases, there are things like foraging guides for
mushrooms, generated by AI full of hallucinations. And so those
can have life or death consequences. And there have been
in many cases life or death consequences. People are developing
companionships with their AI bots and that bot's encouraging their
suicidal tendencies and that. [16:30] And the biggest one in
our mind is these AI notification apps, which you've probably
heard about. It's been an epidemic in so many countries
around the world, especially in high schools. And these are
apps that can take a picture of a person and
create a nude image of that person based on the
photo that you upload. And this has affected hundreds of
thousands of, obviously, primarily women around the world. And not
only AI companies, but also policymakers being so slow to
recognize this problem. [17:00] And doing something about it has
been a real shame. Since 2019, since long before the
latest wave of generative AI advancements, we've had evidence that
this is a problem that's happening on a massive scale.
So when we talk about AI and labor, one very
clear thing that we need to talk about is the
labor that goes into making these large-scale generative AI models.
Yes, they're trained on data from the internet, but they're
also post-trained, as it's called, based on human interaction. And
there is a lot of human [17:30] annotation work that
is necessary to essentially clean the training data, if you
will, that goes into making these models. And this work
is offshored to developing countries. It's trauma-inducing work because day
in and day out, you have to look at videos
of beheadings or racist diatribes or whatever and make sure
that doesn't get into the input or output of AI.
And the working conditions are so precarious that a lot
of these AI companies have often turned to people who
don't have a lot of options in the labor market.
[18:00] Like refugees or people in countries experiencing hyperinflation or
prison labor and so forth. So something is clearly wrong
here and we need new labor rights for this. So
having been critical of companies, I do want to say
that it's not about putting all of the blame on
the companies. There's a lot of personal agency that all
of us need to exercise and we need to use
judgment in knowing when the use of AI is even
appropriate, which is separate from the issue of whether [18:30]
and works or not. A good example of this comes
from the recent election. This example is not in our
book because it's pretty recent, but there was a candidate
in Wyoming, Cheyenne, Wyoming, who wanted the mayor to be
an AI chatbot. And he said that if he were
elected, all the decisions would be made using this chatbot.
And as far as I can tell, it was only
ChatGPT behind the scenes, but he called it VIC for
Virtual Integrated Citizen, which certainly sounds more sophisticated. [19:00] And
yeah, I learned about this because the Washington Post called
me to ask what are the risks of having an
AI mayor. I was very confused by that question, I
kind of blurted out, what do you mean risks of
having an AI mayor? It's like asking what are the
risks of replacing a car with a cardboard cutout of
a car. I mean, sure it looks like a car,
but the risk is that you don't have a car
anymore. I regretted it as soon as I said it,
it was a little bit snarky, but the Post [19:30]
printed it anyway. So let me explain what I mean.
I mean, his point was that politics is very messy
and inefficient, a lot of fighting, etc. Let's make it
more efficient with chatbots. But that completely misses the point.
The reason politics is messy is that that's the forum
we've chosen for resolving our deepest disputes, and to try
to automate that is to miss the very point. So
this is [20:00] More or less one of the last
things I want to say, I'm going to wrap up
in a few minutes, but this is kind of the
framework we use in the book for thinking about how
we should look at any particular AI application. It's a
two-dimensional figure. On one dimension, you have how well does
it work? Does it work as claimed or is it
overhyped or does it not work at all and is
it a kind of snake oil? But on the other
dimension, we have the fact that AI can be harmful
because it doesn't work as claimed and it's snake oil,
or it can [20:30] actually be harmful because it works
well and it works exactly as claimed. So let me
give you examples for each of those kinds of things.
So let's start with the top right here. I mentioned
those video interviews. I mentioned criminal risk prediction. Cheating detection
is, of course, when professors suspect that students are using
AI, they might turn to these cheating detection tools, but
they just don't work, at least as of today. And
they're more likely to flag non-native English speakers, and I've
heard so many horror stories of students [21:00] being falsely
accused. As things stand today, that very much feels like
snake oil to me. But on the bottom right though
are things like mass surveillance using facial recognition. Historically, facial
recognition hasn't worked that well, but now it works really,
really well. And that in fact is part of the
reason that it's harmful if it's used without the right
guardrails and civil liberties and so forth. Then we talk
about content moderation, which we explain in what way it's
overhyped. But basically, [21:30] Our interest in the book is
everything except the bottom left. Those are applications, simple things,
for instance, like autocomplete that kind of fade into the
background and really work well. And our goal is to
have an intervention so we can equip people to push
back against AI that is problematic. You wouldn't want to
read a book that is 300 pages on the virtues
of autocomplete. And I say that because I think that
bottom left corner is very important. There's more in that
corner than we might suspect. [22:00] And to explain that,
let me give you a funny definition of what AI
is. And this definition says AI is whatever hasn't been
done yet. AI is whatever hasn't been done yet. So
what does that mean? What it means is that when
a technology is new, when its effects are double-edged, when
it doesn't work that well, that's when we're more likely
to call it AI. When it starts working well, it's
reliable, it kind of fades into the background. We take
it for granted. We don't call it AI anymore. And
this has happened over and over with many kinds of
[22:30] Automation. Roomba and other robotic vacuum cleaners, I mentioned
autocomplete, handwriting recognition, speech recognition, which I'm sure many of
us use on a daily basis to transcribe. Even spellcheck
was at one point a cutting-edge example of AI. So
this is the kind of AI we want more of.
We want technology that's reliable, that does one thing, does
it well, and kind of fades into the background. So
that's something that we hope that our critical approach can...
[23:00] the industry towards. And our prediction is, and our
kind of optimistic prediction about AI, is that one day
much of what we call AI today will fade into
the background, but certainly not all of it. So for
instance, not criminal risk scoring, there are intrinsic normative questions
that won't go away with making the technology more reliable.
But with self-driving cars, although they are in the news
today often for the wrong reasons because of accidents and
so forth, [23:30] It is going to be the case
that those are solvable engineering problems. There's already been dramatic
progress in solving them. And one day these things are
going to be widely used. They're going to become part
of our physical infrastructure. We'll take them for granted. And
the word car one day will just mean self-driving car,
right? And we're going to need a new name for
what we call cars today, like maybe manual car or
something. And there are some downsides there. We have to
think about the labor implications of gig workers and so
forth. [24:00] It will have been a good thing because
there are one million deaths from auto accidents every year.
So again, that's our vision for a positive kind of
AI. So broadly speaking, in terms of what I think
we need to change in terms of shaping AI for
the better, there are many different recommendations in the book,
but I would cluster them into three big areas. One
is we need to know which applications are just inherently
harmful or overhyped and we probably should not even deploy.
[24:30] And secondly, even when it does make sense to
deploy an AI application, there are often so many risks
and we need guardrails for those. And the third one
is more structural. It's really about the fact that AI
is exacerbating some of the inherent capitalistic inequalities that we
see in our society. So how do we limit companies'
power and redistribute AI benefits? Let me take one last
minute to tell you about a paper [25:00] that we
released just a couple of days ago, which is a
follow-up to AI Snake Oil. AI Snake Oil looks at
what's going wrong with AI today and how do we
fix it. Our new paper is called AI as Normal
Technology, and it's kind of a vision for AI over
the next maybe 20 years. It's taking a longer-term look,
and it's trying to give a framework for thinking about
AI that's an alternative to the major narratives that we
have today. There are three major narratives about AI today.
[25:30] The first one is that it's superintelligence that will
usher in a utopia. The second one is closely related,
it's a superintelligence, but it will do us rather than
benefit us. And the third one is that we should
be very skeptical about AI, it's just a fad, it's
so overhyped, it's going to pass very soon. And our
approach in AI Snake Oil is the middle ground. It
doesn't fit into one of these narratives, but these three
narratives are so compelling that we're often thought of as
saying that [26:00] AI is a fad that's soon going
to pass. That's not what we're saying. But especially in
the new paper, we're making that very concrete. We're giving
a fourth alternative way to think about AI. And this
is closely modeled on what we know from past technological
revolutions, like the industrial revolution, like electricity, like the internet.
We do think AI is going to have transformative effects,
but we think they're going to unfold over a period
of many decades as opposed to suddenly. It's going to
have both good and bad effects. We think a lot
of the super intelligence [26:30] catastrophic risks have been greatly
exaggerated. We think that we're already in a good place
to know how to address some of those risks if
they do come up, and on the basis of all
of this we have some policy ideas for steering and
shaping AI in a more positive direction. So I'll stop
here and I really look forward to the conversation. Thank
you so much. Thank you. [27:00] These are fancy chairs,
as long as I don't fall off them. All right,
that's fantastic, Arvind. Thank you for giving a very, very
succinct but very effective summary of the book. So I
want to start from the predictive AI part. So I
think that was one of the items in the book
that I thought was super interesting and super revealing. But
I want to [27:30] and understand where the more foundational
concerns about predictive AI are coming from. And I guess
as an economist, perhaps one place one could start is
by distinguishing one-person decision problems or one-person interaction problems versus
social problems in which there is an interaction. So if
you, for example, build an AI tool for a runner
[28:00] to decide when, say for example, she's going to
need more liquids, or when she's had enough with the
running or something like that. That's sort of a predictive
tool, but it doesn't have this social interaction aspect. It
still has the human agency, so you might say, well,
human agency means we can never predict anything, but I
think I'm not sure whether you want to go there,
or is it more in these game theoretic situations where
what I do will depend on what others will do?
[28:30] there are these complex interactions that we don't understand.
And I guess if it's the latter, is there a
way to, for example, cut some of the more complex
things into smaller pieces and make some progress? For example,
I don't see Sendhil here, but Sendhil's very interesting work
on bail could we, that's a social problem, but could
we reduce it with the right guardrails to like a
decision problem for a judge? [29:00] My guess is it's
not going to be easy, but perhaps. Thank you, that's
a fantastic question. And yes, Sendhil and others have a
great paper, Prediction Policy Problems, that lays out their vision
for how to use what we call predictive AI for
various things, such as fail and other things. And I
was mentioning that our work is based on some papers
we wrote, the main one on this particular question is
called Against Predictive Optimization, which is sort of intended as
a counterpoint specifically to the prediction policy problem. [29:30] And
to your point, exactly, that if we were using AI
to predict for a runner, you know, when they might
need fluids or whatever, certainly doesn't raise these concerns at
all. Yes, it is something about the social nature of
it. Specifically, it's about the fact that an entity with
power is exercising that power over an individual. And there,
I think we need to go beyond concerns of accuracy
and economic efficiency and so forth and ask from a
philosophical perspective, when is this exercise of power justified? [30:00]
So in our paper, we actually did engage with philosophers
a little bit and we read that literature and tried
to connect it with these more concrete AI questions. So
while we do say that the accuracy is very poor,
you know, how can we do this when it's only
slightly better than the flip of a coin, even if
the accuracy was much better, at a fundamental normative level,
we do think, again, don't want to go into too
much detail for reasons we talk about in the paper,
when the relationship is that of exercising power [30:30] I
think that's a very important point, that many of these
things, I think the statement that technology is never neutral,
that's now part of the folklore, but it's not that
it's neutral. You know, new technologies really change the power
balance, especially with large corporations, which I guess is a
good segue to my second question, which is generative AI.
So I thought the generative AI discussion was very interesting
as well. [31:00] So one take, which I think is
close to my view, is there are a lot of
very exciting capabilities of generative AI, but there aren't that
many applications. And I think I don't see pretty much
any applications except in very few areas like programming subroutines,
etc., which is really going to change yet the production
structure. I think that's not exactly the way you put
it. [31:30] I think it's similar to, so is there
a fundamental reason for that? Or is this just a
passing phase? Yeah, so I completely agree with you that
that's the state of things right now. Where we might
disagree maybe a little bit is that I'm not so
sure it's fundamental. I think it can change in the
future and it's already changing now. And let me explain
what I mean. And this is a big part of
what we get into in the AI as Normal Technology
paper. [32:00] When ChatGPT came out, the fact that it
was so general purpose that you could do different tasks
simply by changing the prompt really misled, I think, not
just a lot of users, but also the companies themselves
from talking to many developers in the AI industry into
thinking that this was a new paradigm of software development.
That this had obviated the need for building software to
do specific things for you, software in the legal sector
or software for helping you with your writing. [32:30] or
whatever it is, then you can use these general-purpose models.
And going forward, all that was going to be needed
is prompting. And that approach, it was tried for a
year or two and has miserably failed. And we analyze
in our newsletter, for instance, we have an AI snake
oil newsletter where we use the foundational approach in the
book to analyze ongoing developments. Why many products that were
simple wrappers around large language models and tried to actually
get them to do useful things in the real world
instead of simply spitting out text, those have [33:00] pretty
bad failures. So there was a device called the Rabbit.
Do folks remember this? And then there was a Marcus
Brownlee review saying it was the worst thing he'd ever
reviewed, and there was a little bit of a scandal
about that and so forth. So that is exactly an
example of what you pointed out, which is that the
capability is there. These large language model-based agents are capable
of doing very interesting things like navigating a website, doing
shopping for you. But the thing is, because they haven't
developed products around them and gotten the reliability rate up
from, let's say, [33:30] like 80% where it is now
all the way to 99.99%, which is something we expect
any software product to have. These are pretty much dead
on arrival. People are complaining that it ordered their product
to the wrong address. Would you use a product a
second time if it did that? So that's an example
of where companies have dropped the ball in translating those
capabilities into products. They are changing their approach now. I
think there is a very good chance that we're going
to see a mushrooming of products in the few years
coming up. [34:00] I didn't mean to suggest that it
was fundamental, but I think I'm also not convinced it's
going to go away very quickly. I guess one reason,
which is different from the ones that you've articulated, so
let me try that on you, is every job is
a very complex bundle of tasks. And the way that
we've done automation in the past is that we've done
careful or semi-careful division of labor so that certain tasks
can be separated. [34:30] or organizations can be changed, it
requires a lot of specific knowledge for the occupation, for
the industry, a lot of tacit knowledge. And I think
the approach of the leading AI companies has been, well,
we're going to go to AGI or very close to
AGI, everything can be done, so we don't need any
of this tacit knowledge, so we're just going to throw
these foundation models and they're going to do it. And
I think that's never going to work because even with
the very fast advanced [35:00] A foundation model is not
going to be able to do everything that even an
auditor does. And when you go to an educator or
to a health professional, I think it's very unlikely. So
you really need this tacit, very specific domain knowledge. So
I don't see that path being followed yet. 100% agree.
I think this is another area where AI developers really
fooled themselves. I think there was misleading intuition from the
last few years of rapid AI progress, whereby [35:30] scaling
up these models, and by training them on bigger and
bigger chunks of the internet, there were more and more
emergent capabilities. That approach has run out. And not only
because they're already training on all of the data they
can get their hands on, but also because the new
things that are left for these models to learn are
exactly things like tacit knowledge. There is a way to
learn tacit knowledge, but it is not in the passive
way that models are being trained right now. It is
by actually deploying models or AI systems, even relatively [36:00]
unreliable AI systems in small settings in different domains on
a sector-by-sector basis, not in a general-purpose way, and learning
from those interactions with real users and real domain experts.
This is the kind of positive feedback loop that we've
had, for instance, with self-driving cars. The reason that it
took about two decades from the first demonstrations of successful
self-driving to getting them to a place where they're able
to autonomously ferry people on the roads right now is
that you have to slowly scale up. You drive a
thousand miles and then you collect data that allows you
to... [36:30] improve your reliability. Now it's reliable enough to
drive 10,000 miles, and then you go to 100,000, et
cetera. That's a very slow process. We predict that we're
going to see that kind of slow feedback loop going
forward on a sector-by-sector basis. Okay, well, I think that's
a segue for the next question, which I wasn't sure
whether I was going to ask because you wisely stay
away from AGI a lot in the book. But I
mean, I guess here is the argument that [37:00] many
people have in their mind, which makes something like AGI
a default position. You know, at the end, a human
mind is a computer, whatever substrate it uses, it's a
computing machine of sorts, well, we're going to build better
and better computing machines, so therefore we'll go to AGI.
So I think then, I think this is sort of
a bait and switch, then it rather puts anybody that
says, well, show me the money in a defensive position.
But if we were in that defensive position [37:30] or
we would have to say, well, here are the bottlenecks
that you haven't taken into account. And I would be
curious to know whether you would completely avoid being put
in that position, or you have something to say about
the presumption or the bottlenecks. Yeah, no, I'm more than
happy to talk about it. These are certainly some of
our more controversial views, at least within the tech community.
So let me say two things to this. One, this
has been consistently predicted. [38:00] throughout the history of AI,
for more than 70 years. When they first made these
what are called universal computers, we just call them computers
now, but back then they were called universal computers because
it was a very new concept that you could build
one piece of hardware to do any task by programming
it appropriately, as opposed to building special purpose hardware for
each particular task. The excitement around that was exactly similar
to the excitement around general purpose, you know, generative AI
models today. They thought, we've done the hard part, the
hardware, it's right there in the name! [38:30] And now
we just need to build the software to emulate the
human mind. And they thought that that was only a
couple of years away. The pioneering 1956 Dartmouth Conference, they
proposed a quote-unquote two-month, ten-man effort to make very substantial
progress towards AGI, which was just called AI back then.
So over and over, while it might be possible in
principle that we can have software do all the things
the human mind does, AI developers have been so off
[39:00] in knowing how much the gap is between where
things currently are and where we need to be. So
that's one thing. The second thing, I know we're running
out of time, so let me just very quickly say,
is we talk about this in the book in chapter
five. In our view, human intelligence is not primarily a
consequence of our biology, but rather our technology. The fact
that we've been using our technology for decades, for centuries,
to learn more about the world. The most prized knowledge
that we have that allows [39:30] us to do things
that we most associate with intelligence, whether it's medical testing
or economic policy, these are things that we learned by
doing large-scale experiments on people. So we predict that very
soon these computational limits are not going to matter, but
the thing that is going to hold AGI back is
not being able to easily transcend learning this knowledge from
what humans have actually learned already and creating new knowledge
for itself, because that's going to require [40:00] same kind
of bottlenecks that we ourselves have faced with experiments, scaling,
ethics, and so forth. And we're not going to let
AI do experiments on millions of us without any oversight.
And so that is going to put very, very strong
speed limits. Great, that's an excellent point. I think we're
running out of time, so I want to bring it
to a topic that's actually much closer to our initiative,
which is our concerns about whether we're doing the right
kind of AI. So I think [40:30] David Simon and
I, all three of us have these ideas, some based
on intuition, some based on empirical facts, some based on
history, that there is a more productive way in which
you can develop AI, especially what we call pro-worker AI,
which aims at increasing worker skills, expertise, productivity, create new
tasks or capabilities [41:00] to do more sophisticated tasks, and
then we're worried whether we'll actually ever get there on
the current path. And I guess you have sort of
very nicely cataloged various mistakes that people are making in
terms of banking, or at least pretending that they're banking
on AI that's unlikely to work, or if it works,
it's not going to be that great. AI hype, perhaps
that's leading to AI overinvestment, perhaps it's leading to the
wrong kind of AI investment. But I guess at least
[41:30] I didn't see it, or perhaps I missed it,
that next step in the book, which is therefore the
wrong types of innovation effort, R&D, etc., is being made,
the wrong kind of startup energy is coming, and whether
we can do anything about that other than, of course,
inform the public, inform policymakers with books and conversations like
this. But is there a more sort of an agenda
of that sort that would make you even more of
an expert in that? I think there is a little
bit, and I think [42:00] That's exactly the critical question,
and I'm so glad that you all are looking into
that. And I think it needs perhaps economists more than
computer scientists. But what I can say from a computer
science perspective is that when we look at what companies
are doing, right now the market is not rewarding that.
So an example of where this plays out is the
use of AI by students. I know we're talking about
labor, but I think it's somewhat similar. So the initial
uses of generative AI [42:30] I work primarily for cheating
or other things that are maybe not the best ways
to use them. We know there are good ways to
use them. We know that AI, if properly configured, can
be a very good tutor despite its limitations such as
hallucinations. I use AI very heavily for learning. I haven't
stopped using books, but there are some advantages of using
AI. Happy to get into that in the Q&A. But
it's remarkable that only, I think, a couple of weeks
or maybe a month ago that Anthropic came up with
an AI tutor, which is just a simple customization [43:00]
mode where it's not just giving out answers to the
student but rather promoting their critical thinking, right? And it's
striking to me that that took them so little work,
but it took them, you know, two and a half
years or whatever of people just constantly complaining in order
to do, right? And so yes, we can provide lots
of technical ideas, but ultimately we need to either change
the incentives for companies through regulation or have much more
investment in other organizations, maybe NGOs, who are going to
develop [43:30] these AI applications with the public interest in
mind, instead of leaving it to the AI companies. Thank
you very much, Arvind. I think that's a great time
for us to transition because I'm sure many people have
burning questions for you. The way we're going to organize
this is there are two mics over there. Those of
you who want to ask questions, if you don't mind
lining up, and then we can take one from each
side in alternating order. Why don't we start? [44:00] Thank
you very much, a wonderful talk. And I just asked
a quick layman question as a user, you know, for
AI for over a year. You know, my question is
that how much you can tolerate the error that generates
from AI, you know, giving you the answer. For instance,
recently I, you know, tried to ask AI a question
of a citation or quotation from a famous person. [44:30]
Okay, and then I get the answer and then I
post it on my blog and I get embarrassing because
I asked the professor, he said that I never say
such statement. So that AI create or imagine that person
X say something like this. I would say that AI
give a lot of convenience, pattern recognition and very convenient,
but I would say 10% of [45:00] Thank you. Yes,
hallucinations are a big problem with generative AI. These are
fundamentally stochastic technologies. Even if you could somehow clean all
the training data and make sure that you only train
it on true statements, the problem would remain because at
generation time it is kind of remixing the statistical patterns
in its training data. The hallucination rates have gone down
quite a bit over the last couple of years, but
they're not zero. I don't think they're going to reach
zero in a very short period. [45:30] And I have
also had the experience of people emailing me to ask
for my papers, and they're like, hey, where is it?
I couldn't find it online. It turns out it was
made up by AI and attributed to me. And so
what we train people to do is to not just
think about using AI generally in your work, but identify
specific areas of your workflow, and in each of those
uses of AI, you have to have an answer to
why is it easier to verify the answer to this
question than to have done this work myself. [46:00] And
if you do have an answer, it might save you
time or enhance your creativity, as the case may be.
Thank you. Professor, I wanted to bring back again this
topic of the fairness or maybe bias of the algorithms.
About six months or a year ago, Sam Altman came,
and when someone asked him about the bias of the
algorithms, you can say that, for example, in the criminal
justice system, [46:30] it's easier to change the algorithm than
the bias from the humans. And I said okay maybe
that's compelling to be honest for me it was like
understandable. What do you say about that? What do you
think? Is it possible? Do you think it's better who
sets what the bias is? Yeah, thank you. It's a
good debate. Sendhil has also made that claim. He had
an op-ed in the New York Times literally saying it's
easier to fix biased algorithms than biased humans. And I
very much see that [47:00] I have a slightly different
view. I think in theory it's certainly possible to fix
certain kinds of biases in algorithms. It might just be
a matter of changing, you know, a parameter in the
code, and there are many computer science techniques to do
that. The problem is not technical. The problem is one
of incentives and transparency and things like that. A lot
of the time, you don't have transparency from the companies
who are building [47:30] criminal justice algorithms. They might say
it's proprietary, it's a trade secret. So in the case
of COMPAS, even though it's been about a decade since
that investigation, no changes have been made. Because actually, you
cannot fix it without introducing disparate treatment. If you were
to fix it in the algorithm, you have to have
different weights or different treatments, different thresholds for different categories
of people. And that actually would violate the law. And
these are things that human judges account for in a
very subtle way when they're making their decisions. [48:00] do
them in algorithmic systems, we have to do them in
very crude ways which, even if theoretically possible, end up
not being practically possible because of various constraints. Thank you.
Hi, thank you for the book and the conversation. So
the question I wanted to ask, kind of, in the
book and in the talk, right, there's this kind of
general statement that it's like, many predictive AI applications are
unlikely to work and there's hope for Gen AI. And
I want to ask, basically, is that predominantly a statement
about [48:30] from your perspective, the underlying technologies are the
settings in which those technologies are employed. The reason I
ask that is because I work on AI for climate
change-related applications, right? There are certain settings like solar power
prediction where you could use a predictive model or a
generative model. And also there are kind of some tides
from some of the large technology providers now where there's
this statement of like, we should invest in generative AI
and large models because it's going to solve climate problems.
[49:00] leads to an investment in GenAI rather than other
techniques and all of the sort of energy consumption and
concentration of power that comes with that. And sort of
the statement of like GenAI is better than predictive AI
can kind of lead to those kinds of ties. So
yeah, circling back, the statement about the technologies or the
settings. Yeah, thank you. That's a great question. And it's
exactly the latter. It's a statement about the settings. It's
about the particular applications that we're using these technologies for.
Even if you were to take a generative AI model
and use it in criminal justice, exactly the same [49:30]
You said something about the predictions from people in the
field about how soon AI would reach certain levels has
been a terrible track record. Let me suggest that's a
sample bias, because all the bad predictions get all the
press. [50:00] You never hear about the fact that somebody
once asked John McCarthy what it would take to get
really good artificial intelligence. And he was annoyed by the
question, so he gave a somewhat whimsical answer. But he
said 1.3 Einsteins and he went on from there. That's
not widely quoted because it's not nearly the kind of
thing you can make a big laugh out of. So
let me caution you on that. Thank you, I appreciate
that. I should clarify, you know, I had a somewhat
superficial presentation at that point. [50:30] but there was a
deeper point behind it, which is not so much that
the founders were wrong, but they were wrong for fundamental
structural reasons, in that they were, I'm not blaming them,
they were not able to see what are the kind
of steps in the ladder, if you will, we use
the metaphor of a ladder in our book to discuss
progress in AI. When you're standing on one step of
the ladder, we claim it's impossible to know what the
future steps on the ladder are, so it's really about
that deeper point. But thank you, I appreciate the correction.
One other quick point [51:00] You got what I'll call
an inexpensive laugh out of the idea that the predictive
programs and their AUC was only about 70, so they
weren't much better than flipping a coin. You have to
ask about the baseline. How good were the people doing
this task? Because if the people doing this task are
at 55%, then 70 is pretty damn good. Yeah. Okay.
All right. So the people were exactly at the same
level [51:30] of the algorithm and not even trained judges,
just laypeople. And not only that, whatever you can accomplish
with state-of-the-art algorithms, you can get with a two-variable regression
model. And those two variables are the defendant's age and
the number of prior arrests. And we talk about why
the use of the age is actually morally problematic. So
essentially the logic behind these systems is if you've been
arrested a lot in the past, you're going to be
arrested a lot in the future. That is the [52:00]
And it doesn't look good for the algorithm. Maybe I'll
go to another question. We have only less than three
minutes left, so please very short questions at this point.
I had a question about how you calibrate investment across
different types of technologies. So maybe you have [52:30] Yeah,
definitely. So this relates to an issue that we call
herding in the AI community. And in every research community,
you know, there are fashionable ideas, people cluster around them.
It's hard to compare this between fields, but just kind
of based on vibes, it seems like there's more of
this going on in the AI community than [53:00] So
today all of these fancy generative AI systems are based
on neural networks, which were sidelined for more than 20
years because people thought that they were completely outperformed by
another technology called support vector machines, which people would laugh
at in today's context. So why did that happen? There
wasn't enough diverse exploration of different paths. So I do
think it might be hard to compute the return on
investment, but it seems clear that there needs to be
more of a risk preference [53:30] I think we've seen
an ever-increasing gap between productivity and wages. I think there's
a big argument for the stagnation of wages, basically just
occurring probably due to a number of factors, but including
computation kind of replacing and abstracting a lot of the
work. How do you view maybe the impacts of something
like AI maybe impacting the productivity? [54:00] and how that
might also affect the wages and how can we correct
that. That's a question for you, I think. But I
don't want to hear from you. No, no, no, please
go ahead. I want to hear from you. Well, this
is what we spent a good chunk of our waking
hours that not just automating work, which will of course
happen and should happen, but also finding AI users that
will increase the information and the capabilities [54:30] there is
a lot of fear and backlash against AI, and I
wanted to know your thoughts on what might be contributing
to that, and also how people in either tech research
or tech industries, how they can address those fears. Definitely,
lots of thoughts on this. [55:00] But I know we're
running out of time, so let me keep it short.
And yes, you're absolutely right, many more people, according to
public opinion surveys, are worried about what AI will mean
for them than are excited about it. And I think
this is almost entirely a statement about capitalism than it
is about AI. It varies a lot between different countries
based on the kinds of worker protections that people have
come to expect, etc. It dramatically moderates their reaction to
these exciting slash worrying [55:30] technological developments. And I think
in terms of what can be done about it, I
think there's a lot of room to improve the channels
of communication between the AI industry and research community with
the general public. We've talked a lot about how in
many ways people in general, workers in different domains have
a much better understanding of AI's potential and limits and
their particular application like law or medicine or whatever than
AI developers do. And so AI developers would benefit a
lot from understanding that and not making these [56:00] overhyped
claims, but at the same time, I think people deserve
to understand why is it that companies are confident enough
to make these trillion-dollar bets, understand new emerging capabilities, which
frankly almost feels like a full-time job to kind of
stay on top of. I think companies can do a
lot to ease actual public understanding as opposed to just
hyping up capabilities. So I think communication could improve in
both directions. Thank you so much. Well, thank you very
much, Arvind. That was wonderful. [56:30] I'm just gonna add
that it's a testament to how interested people are. They
could have stayed here for another half an hour. But
thank you.
------------------------------------------------------------
[Audio] Keeping 114 chunk files for debugging
[Audio] Chunks location: /Users/jaesolshin/Documents/GitHub/yt-trans/temp_audio

Transcript saved: /Users/jaesolshin/Documents/GitHub/yt-trans/transcript/AI_Snake_Oil_What_Artificial_Intelligence_Can_Do,_What_It_Can’t,_and_How_to_Tell_the_Difference.txt

[SUMMARY] Generating summary...
Generating summary with gpt-5-mini...
Summary generated successfully
Summary saved: /Users/jaesolshin/Documents/GitHub/yt-trans/transcript/AI_Snake_Oil_What_Artificial_Intelligence_Can_Do,_What_It_Can’t,_and_How_to_Tell_the_Difference_summary.txt
Summary copied to: /Users/jaesolshin/Downloads/AI_Snake_Oil_What_Artificial_Intelligence_Can_Do,_What_It_Can’t,_and_How_to_Tell_the_Difference_summary.txt

Transcript copied to: /Users/jaesolshin/Downloads/AI_Snake_Oil_What_Artificial_Intelligence_Can_Do,_What_It_Can’t,_and_How_to_Tell_the_Difference.txt

[SUCCESS] Transcription completed successfully!
