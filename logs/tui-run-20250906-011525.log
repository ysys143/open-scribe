[youtube] Extracting URL: https://youtu.be/fryDDMI3kfQ?si=SVVz2KtTLq4WSf8m
🎥 Starting transcription: https://youtu.be/fryDDMI3kfQ?si=SVVz2KtTLq4WSf8m
Engine: gpt-4o-mini-transcribe

Extracting video information...
Title: [AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자
Duration: 2308 seconds
Uploader: 메타코드M

Downloading audio...
Downloading audio from YouTube...
[youtube] fryDDMI3kfQ: Downloading webpage
[youtube] fryDDMI3kfQ: Downloading tv simply player API JSON
[youtube] fryDDMI3kfQ: Downloading tv client config
[youtube] fryDDMI3kfQ: Downloading tv player API JSON
[info] fryDDMI3kfQ: Downloading 1 format(s): 251
[download] Sleeping 5.00 seconds as required by the site...
[download] Destination: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/[AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자 [fryDDMI3kfQ].webm

[download]   0.0% of   31.46MiB at  529.65KiB/s ETA 01:01
[download]   0.0% of   31.46MiB at    1.31MiB/s ETA 00:24
[download]   0.0% of   31.46MiB at    2.77MiB/s ETA 00:11
[download]   0.0% of   31.46MiB at    5.50MiB/s ETA 00:05
[download]   0.1% of   31.46MiB at    6.21MiB/s ETA 00:05
[download]   0.2% of   31.46MiB at    8.83MiB/s ETA 00:03
[download]   0.4% of   31.46MiB at    9.77MiB/s ETA 00:03
[download]   0.8% of   31.46MiB at   12.21MiB/s ETA 00:02
[download]   1.6% of   31.46MiB at   17.96MiB/s ETA 00:01
[download]   3.2% of   31.46MiB at   25.36MiB/s ETA 00:01
[download]   6.4% of   31.46MiB at   34.29MiB/s ETA 00:00
[download]  12.7% of   31.46MiB at   30.43MiB/s ETA 00:00
[download]  25.4% of   31.46MiB at   30.86MiB/s ETA 00:00
[download]  30.3% of   31.46MiB at   33.26MiB/s ETA 00:00
[download]  30.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  30.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  30.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  30.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  30.4% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  30.5% of   31.46MiB at   46.26MiB/s ETA 00:00  
[download]  30.7% of   31.46MiB at   80.02MiB/s ETA 00:00
[download]  31.1% of   31.46MiB at   85.96MiB/s ETA 00:00
[download]  31.9% of   31.46MiB at   15.17MiB/s ETA 00:01
[download]  33.5% of   31.46MiB at   23.84MiB/s ETA 00:00
[download]  36.6% of   31.46MiB at   33.97MiB/s ETA 00:00
[download]  43.0% of   31.46MiB at   37.82MiB/s ETA 00:00
[download]  55.7% of   31.46MiB at   30.98MiB/s ETA 00:00
[download]  61.4% of   31.46MiB at   34.04MiB/s ETA 00:00
[download]  61.4% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  61.4% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  61.4% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  61.5% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  61.5% of   31.46MiB at   28.27MiB/s ETA 00:00  
[download]  61.6% of   31.46MiB at   46.12MiB/s ETA 00:00
[download]  61.8% of   31.46MiB at   75.31MiB/s ETA 00:00
[download]  62.2% of   31.46MiB at   64.48MiB/s ETA 00:00
[download]  63.0% of   31.46MiB at   56.84MiB/s ETA 00:00
[download]  64.6% of   31.46MiB at   18.78MiB/s ETA 00:00
[download]  67.8% of   31.46MiB at   28.24MiB/s ETA 00:00
[download]  74.1% of   31.46MiB at   35.94MiB/s ETA 00:00
[download]  86.8% of   31.46MiB at   43.79MiB/s ETA 00:00
[download]  92.3% of   31.46MiB at   46.63MiB/s ETA 00:00
[download]  92.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  92.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  92.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  92.3% of   31.46MiB at  Unknown B/s ETA Unknown
[download]  92.4% of   31.46MiB at   26.30MiB/s ETA 00:00  
[download]  92.5% of   31.46MiB at   41.63MiB/s ETA 00:00
[download]  92.7% of   31.46MiB at   73.30MiB/s ETA 00:00
[download]  93.1% of   31.46MiB at   70.13MiB/s ETA 00:00
[download]  93.9% of   31.46MiB at   63.49MiB/s ETA 00:00
[download]  95.5% of   31.46MiB at   55.04MiB/s ETA 00:00
[download]  98.6% of   31.46MiB at   58.06MiB/s ETA 00:00
[download] 100.0% of   31.46MiB at   58.10MiB/s ETA 00:00
[download] 100% of   31.46MiB in 00:00:00 at 33.04MiB/s  
[ExtractAudio] Destination: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/[AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자 [fryDDMI3kfQ].mp3
Audio downloaded: [AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자 [fryDDMI3kfQ].mp3

Transcribing with gpt-4o-mini-transcribe...
[GPT-4o-mini] Processing: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/[AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자 [fryDDMI3kfQ].mp3
[GPT-4o-mini] Using hybrid mode for accurate timestamps...
[Hybrid] Step 1: Fetching YouTube transcript with timestamps...
Found auto-generated transcript in ko
[Hybrid] Step 2: Getting high-quality transcription from gpt-4o-mini-transcribe...
[GPT-4o-mini] Processing: /Users/jaesolshin/Documents/GitHub/yt-trans/audio/[AI Agent 개념, 설계, 개발] 이 영상 하나로 끝내드립니다ㅣ5년차 Data Scientist 현직자 [fryDDMI3kfQ].mp3
[GPT-4o-mini] File is large, using chunking strategy...
[Audio] Using project temp directory: /Users/jaesolshin/Documents/GitHub/yt-trans/temp_audio
[Audio] Splitting 2308.2s audio into 4 chunks of 600s each
[Audio] Created chunk 1/4: chunk_000.mp3
[Audio] Created chunk 2/4: chunk_001.mp3
[Audio] Created chunk 3/4: chunk_002.mp3
[Audio] Created chunk 4/4: chunk_003.mp3
[GPT-4o-mini] Transcribing 4 chunks...

                                                                                                    
Overall: [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 2.5% (0.1/4 chunks) | Speed: 21732.15 chunks/min | ETA: 0m 0s
                                                                                                    
Overall: [█████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░] 32.5% (1.3/4 chunks) | Speed: 2.63 chunks/min | ETA: 1m 1s
[GPT-4o-mini] Chunk 4: 2654 chars

                                                                                                    
Overall: [██████████████████████░░░░░░░░░░░░░░░░░░] 55.0% (2.2/4 chunks) | Speed: 3.55 chunks/min | ETA: 0m 30s
[GPT-4o-mini] Chunk 2: 3752 chars

                                                                                                    
Overall: [███████████████████████████████░░░░░░░░░] 77.5% (3.1/4 chunks) | Speed: 4.62 chunks/min | ETA: 0m 11s
[GPT-4o-mini] Chunk 3: 3575 chars

                                                                                                    
Overall: [████████████████████████████████████████] 100.0% (4.0/4 chunks) | Speed: 5.76 chunks/min | ETA: calculating...
[GPT-4o-mini] Chunk 1: 3757 chars

[WorkerPool] Completed 4 chunks in 0m 41s
[WorkerPool] Worker 13572796416: Processed 1 chunks, avg time: 29.7s
[WorkerPool] Worker 6283145216: Processed 1 chunks, avg time: 37.2s
[WorkerPool] Worker 6299971584: Processed 1 chunks, avg time: 40.3s
[WorkerPool] Worker 6266318848: Processed 1 chunks, avg time: 41.6s
[GPT-4o-mini] Completed: 4/4 chunks
[Audio] Keeping 4 chunk files for debugging
[Audio] Chunks location: /Users/jaesolshin/Documents/GitHub/yt-trans/temp_audio
[Hybrid] Step 3: Correcting with gpt-5-mini...
[Subtitle Corrector] Found 230 segments from YouTube
[Subtitle Corrector] Using gpt-5-mini for correction
[Subtitle Corrector] Error during correction: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}
[Subtitle Corrector] Falling back to YouTube transcript
[GPT-4o-mini] Streaming transcription...
------------------------------------------------------------
[00:00] 아, 네. 그러면은 이제 시작하도록 하겠습니다. 우선 간단히 제
소개를 말씀드리자면은 저는 우선 데이터 사이 유합학과 대학원을 이제 졸업을
했고 [00:10] 어 최근에 레그 마스터라는 책 지필도 진행을 아,
네. 집필도 한 바가 있습니다. 그리고 어 작년에 이제 어
스터디 사람들이랑 같이 그냥 [00:20] 비콘테스트 나와서 어 우수상도 수사하고
저희 다른 팀분들은 이제 대표 그 대상도 수상하셨었고요. [00:29] 현재
저는 이제 스타트업 5년차 데이터 사이언티스트고 어 데이터 분석 및
모델링 업무를 맡았습니다. 예. [00:39] 네. 어 우선은 저의 조요
업무는 이제 머신러 모델 개발 그다음에 데이터 분석 그리고 최근
들어서 이제 AI전트 설계 및 개발을 진행을 하고 [00:50] 있습니다.
어 뭐 대화형 채법 구축에 대해서도 뭐 개발을 하고 뭐
AI 기반 리포트 생점 시스템 개발도 진행을 합니다. 그러면은 우선
[01:00] AI에트에 대해서 좀 이야기를 들 드려야 될 거 같은데
최근에 AI 에이전트에 관한 관심이 쏠리면서 영어 사용에 [01:10] 어
대한 혼선 또한 발생하고 있습니다. 어 우선 그 삐트 공는
안 되냐고 여쭤보셨는데이 부분에 있어서 추소에 이제 다시 답변 드리도록
[01:21] 하겠습니다. 우선은 이제 AI 에이전트에 관한 관심이 쏠리면서 용어
사유에 대해서 어 조금 혼선이 있는데이 용어 정리를 좀 해
보도록 하겠습니다. 어이 AIR 에이전트에 [01:33] 대해서 좀 말씀을 드리기
전에 전통적인 가압론에서 에이전트는 이제 보통 환경을 인식하고 그에 따라
행동하는 개체로 정의를 합니다. [01:42] LM가 도래하면서 AI를 탑재한 AI에트가
등장을 하게 되었고 간단한 반복적인 작업을 자동화하는 것을 넘어 자율성이나
의사 결정을 가진 시스템이 [01:54] 이제 만들어지게 됩니다. 한마디로 조금
요약해서 말씀드리자면은 LM을 기반으로 외부 도구와 윤동하고 스스로 판단하고 작업을
수행하는 자율 시스템이라고 생각하시면 됩니다. [02:07] 환경의 변해도 동적으로 계획을
조정할 수 있다는 점에서 기존 룰 기반 자동화와는 차별이 됩니다.
어, 여기에 이제 AI 기반 개인화, 영화 [02:17] 추천 자동화
프로세스를 좀 보실 수 있는데 여기에 AI트가 어떤 역할을 하는지
좀 볼 수 있습니다. 우선 유저와 인터랙트를 하기 전에이 다른
[02:28] 많은 유저들에 대한 데이터로 수집을 하게 됩니다. 그래서 여기
2번 쪽을 이제 보시면 되는데이 2번 쪽에 어 뭐 유저들
별로 액션 뭐 사이파이 뭐 [02:39] 트릴러 막 이런 식으로도를
뭐에 대한 데이터를 수집을 한 것을 보실 수 있습니다. 그다음에는
3번 쪽으로 가시게 되면은 영화 메타데이터와 설명을 이제 분석을 하게
[02:51] 됩니다. 각 영화와 영화의 장르, 줄이 등장 인물 평가
분위기 등 LM을 이해하고 요약을 하게 됩니다. [03:00] 여기에서도 어
어떤 영화인지 그다음에 뭐 어떤 장르인지 그리고 연도 이런 것들을
이제 있는 것을 보실 수 있습니다. 그리고 나서 이제 4번
[03:10] 쪽으로 넘어가게 되시면은이 이러한 정보들을 LLM 프로팅으로 이제 줄
수가 있게 됩니다. 뭐 예를 들어서 유저이랑 영화 목록 목록과
[03:21] 설명을 이제 같이 넣어서 프롬큐를 넣어 주면서 해당 유저가
흥미를 느낄 만한 영화를 추천해 줘와 같은 자연 프롬퍼트를 생성을
하게 되고 이제이를 [03:32] 기반으로 해서 얻게된 최근 뭐 관심이
있으면한 영화 목록을 기반으로 LL 기반 자동 이메일을 작성을 해서
어 그 사용자에게 이것들을 전달할 수가 [03:44] 있습니다. 이메일로 작성을
할 수도 있는 거죠. 그래서이 프로세스와 같이 이제 AI가 뭐
마케팅을 또 대응할 수 있는 수준으로까지 확장되었음을 볼 수 있습니다.
[03:56] 그렇다면은이 AI 에이전트에 대해서 배웠으면은 에이전틱 AI에 대해서 조금
더 여어를 설명하도록 하겠습니다. 예. 앤드리과 같은 과학자들은 뭐 에이전틱
AI 뭐 [04:08] 에이전트 에이전트 뭐 여러 가지 용어들이 있는데이
용어들보다 우선 에이전틱이라는 단어를 좀 이해해야 할 필요가 있다고 합니다.이
이 에이전틱이라는 말은 어 더 높은 [04:20] 수준의 자율성, 그러니까
상황 인식 및 적응력을 갖춘 보다 진보된 형태로 목표를 알아서
이제 설정하고 환경을 확습하고 어 알아서 이제 윤리적인 [04:31] 냉락적을
고려하여서 복잡한 결정을 내리는 것을 말합니다. [04:36] 뭐 시스템이 에이젠틱하다
뭐 이런 식으로도 얘기를 할 수 있는데 간단히 얘기해서 에이젠틱하다라는
것은 결국에 사람 손을 덜 타도 된다라는 말이기도 합니다. 그래서
시스템이 [04:48] 에이전틱하다. 시스템이 매우 에이전틱하다라는 말은 아 사람이 개입하지
않고서도 AI가 알아서 이런 것들을 처리할 수 있다. 이러한 시스템이다라고
[04:59] 생각하시면 될 거 같습니다. [05:01] 어 에이전틱 아키텍처에 대해서
이제 설명드리도록 하겠습니다. 이 에이전틱 아키텍처는 이런 A, AI 에이전트들이
스스로 판단하고 협업할 [05:11] 수 있도록 구성된 가상 공간과 워크플로우
구조를 의미합니다. 쉽게 말해서 어 에이전트들이 잘 일할 수 있도록
무대와 규칙을 제공하는 설계 [05:22] 방식이라고 생각하시면 됩니다. [05:24] 여기에서도
에이전틱 레그가 있는데 뭐 예를 들어서 질문이 들어왔었을 때 얘네들이
이제 리트리버로 이게 리트 검색기가 필요한지 필요 [05:35] 없는지에 따라서
결정을 하고 맞에 필요하게 된다면은 어 이제 리트리버 검색기를 갖고
와서이 도구를 이용해서 이제 관련된 문서를 찾아 놓은 [05:46] 다음에이
문서를 기반으로 관련성이 있는지 없는지를 또 LM 자체가 확인을 하고
관련성이 있으면은 최종 답변을 고 관련성이 없으면은 이제 쿼리를 좀
다시 재수정해서 다시 한번 [05:59] 쿼리를 날리도록 하는 방식으로이 에이전트
레그가 간단하게 이런 형식도와 에이전트 에이전트랙 아키텍처의 한 예시라고 보시면
될 거 [06:09] 같습니다. [06:12] 그렇다면 이제 AI 에이전트 요소를
좀 간단하게 설명드리도록 하겠습니다. [06:16] 에이전트릭틱 시스템을 구성하는 핵심 요소인
LLM 툴스 메모리에 대해서 간단히 소개하겠습니다. 우선 첫 번째 LLM은
대규모 언어 모델로 이제 많은 분들이 이제 알고 계시는 [06:26]
최지T와 같은이 큰 LM 모델이라고 생각하시면 됩니다. 어 굳이 LM
안 써도 되고 SLM이라고 작은 모델 언어를 써도 되긴 하지만
그렇게 되면 성능이 좀 어 안 좋아질 수 있다는 [06:38]
점이 있습니다.이 이 LM은 이제 결국에는 추론과 프롬포트 해석을 이제
역할을 하게 되는데 어 에이전트는 이제 문제를이 이해하고 복잡한 작업을
계획하고 그 계획을 바탕으로 이제 [06:50] 반응하는 식으로 이제 방식을
조정해 갑니다. 네. 그리고 두 번째로는 툴입니다.이 도구 같은 경우에는
에이전트가 혼자서 할 수 있는 일에는 한계가 있기 때문에 다양한
외모 [07:01] 시스템과 상자 상호 작용을 할 수 있도록 툴을
사용합니다. 뭐 여기서 보시는 바와 같이 뭐 벡터 서치 엔진을
해야죠 의미적으로 비슷한 문서를 갖고 올 수 있도록 해 [07:12]
주는거나 뭐 웹서치 같이 웹 검색 이런 것들도 뭐 하나의
툴이라고 보실 수 있습니다. 마지막으로는 메모리입니다.이 이 기업 같은 경우에는
에이전트가 단발성 응답에 [07:23] 그치지 않고 이제 지속적으로 일관된 상호
자국은 상호 작용을 하기 위해서 기역 시스템이 필요하게 됩니다. 어
메모리 같은 경우에 단기 메모리 그냥 [07:34] 일시적인 일시적으로 이제
히스토리나 주변 정보를 저장해서 그 바로 직전 맥락 기반의 응답을
생성하는데 사용될 수 있고 장기 메모리 같은 경우에는 [07:44] 여러
세션에 걸쳐서 이제 사용자의 상호 작용을 기억하고 맞춤형 정보를 제공하는데
활용될 수 있습니다. [07:54] 어 이제 어 에이전틱 아키텍처의 유형에
대해서 설명드리도록 하겠습니다. 어 에이전트 아키텍처 유용은 뭐 크게 두
가지로 볼 수가 있는데요. 그건 첫 번째는 싱글 [08:05] 에이전트
아키텍처가 있고 두 번째로는 멀티에트 아키텍처가 있습니다. 각각에 대해서 조금
더 자세히 설명드리도록 하겠습니다.이 이 싱글 에이전트 [08:15] 아키텍처 같은
경우에는 어 우선은 AI 시스템의 구조는 이제 아 아 싱글
에이전트 아키텍처는 이제 하나의 에이전트가 환경을 인식하고 의사 [08:26] 결정을
내리며 행동까지 독립적으로 수행하는 구조입니다.이 이 구조는 단순하고 예측 가능하고
이제 개발과 유지 보수가 쉬워서 어 비용 효율적인 [08:37] 장점이
있지만 어 반대로 이제 확장성과 유연성이 부족해 복잡한 문제나 다양한
도메인을 다루기에는 [08:44] 한계가 있습니다. 보통 LM한테 이제 프롬프트를 너무
그니까 어 LM한테 지시하는 사항들이 길면 길수록 LM이 좀 그런
프롬프트에 대해서 이해를 잘 [08:57] 못 하는 부분들이 있을 수
있어서 이런 것들을 좀 쪼개 주는 역할이 이제 필요하게 되는데
그러 그걸 도와주는게 결국에는 이제 멀티에전트 아키텍처라고 보시면 될 거
같습니다. [09:09] 어이 멀티에전트 아키텍처는 여러 에이전트가 각각의 역할을 맡고
어 상후 협업하면서 문제를 해결하는 구조입니다.이 각 에이전트는 전문적인 [09:20]
기능을 수행하고 유연하며 이제 확장 가능한 시스템을 구성할 수 있습니다.
[09:26] 어, 다만 이제 설계와 조율이 복잡하고 의사 결정 속도가
이제 에이전트가 많을수록 어 진행돼야 될 프로세스가 좀 더 길어지기
때문에 [09:35] 의사 결정 속도가 좀 느려질 수 있는 단점도
존재합니다.이 구조는 그 뭐 업무 자동화나 뭐 멀티도메인 대응, 복잡한
시스템 협업 등 고도화된 AI [09:47] 사용 활용이 필요한 영역에서
적합하다고 볼 수 있습니다. [09:51] 그렇다면 이제 멀티에전트 시스템 패턴이
어떤 것들이 있는지 보도록 하겠습니다. 이제 패럴 해 가지고 이제
병렬적으로 에이전트를 이제 구성을 할 수가 있고요. 인풋으로 뭐 [10:02]
커리가 들어가게 되면은 뭐 두 개의 에이전트가 각각 어 역할을
맡아서 그것들을 이제 처리를 하고 이제 답변을 하는 형식입니다. 어,
이제 여러 에이전트를 각 문제의 여러 [10:14] 부분들을 동시에 작업하는
부분에 있어서 좋은데 이제 여기에서 문제는 이제 오픈 모델 같은
것들을 이용하게 되면은 어 자체 GPU 메모리가 큰 [10:24] 서버가
좀 많이 필요하다는 점이 어 이게 단점이 될 수 있고
그 외에네 그런 부분이 좀 단체이 될 수 있습니다. 포셜
같은 부분에는 이제 [10:34] 어 한 작업의 에이전트의 탄출물이 인접한
다른 에이전트의 토익물로 이어지는 형태로 순차적으로 이제 진행되는 형태라고 보시면
됩니다. [10:43] 이런 경우에는 어 단일 에이전트를 이용을 해서 뭐
두 개의 그 뭐 프롬포트 그러니까 시스템 프롬포트를 좀 달리
줘서 에이전트가 하는 역할을 다르게 해서 그런 것들을 할 수
[10:55] 있지만 그러 그럼에 따라서 GPU 외모리가 국회가 많이 필요하진
않지만 아 반면에이 시간이 조금 많이 걸릴 수 있다라는 단점이
있습니다. 루프 [11:06] 같은 형태에는 에이전트간 작업을 반복적으로 수행해서 상호간의
피드백을 통해 작업물의 성능을 향상시키는 아키텍처가 있고요. 그다음에 라우터라고 이제
중앙의 라우터는 이제 [11:19] 작업이나 입력에 따라서 호출할 에이전트를 결정을
하게 됩니다. 뭐 예를 들어서 뭐 책 그냥 일반 대화하면은
일반 대화로 가든지 아니면 좀 약간 외부 도구가 필요한 어
[11:32] 관련된 문서를 좀 찾아야 되는 부분이 있다면은 어 서치로
이제 가도록 에이전트가 가도록 아웃풋을 하든지 이런 식으로 이제 결정해
주는 어 패턴이라고 보시면 됩니다. [11:44] 그다음 어그리게이터도 있는데 이분들은
이제 산출물을 집게해서 에이전트를 통해 수지빛 합성해서 최종 결과물에 기호하는
부분이 있습니다. 뭐 여러 [11:54] 앞에서 뭐 패랄에서 병렬로 여러
가지 두 개의 에이전트에 대한 답변을 받아와서 그런 것들을 이제
종합해서 최종 산추물로 이제 나오게 되는 그런 [12:05] 패턴이라고 보시면
될 거 같습니다. [12:08] 그다음에 또 설명드릴 것이 이제 수평적
구조와 수직적 구조인데요. [12:13] 호리전탈 수평적 구조 그다음에 리티컬 수집
구조인데 먼저이 네트워크이 수평적 아키텍처 같은 경우에는 각 에이전트가 동등한
위치에 지위에서 [12:25] 이제 상호 협업하면서 문제를 해결하는 방식입니다. 어이
구조에서는 분산된 자율성과 그룹 기반 의사 결정이 특징이고 다양한 아이디어를
창출하고 [12:36] 병렬 처리가 가능하다는 장점이 있습니다. 어, 특히 뭐
브레인스토밍이나 복잡한 문제를 해결하는 데서 유용하다고 합니다. [12:44] 하지만 이제
에이전트 간율이 좀 어유렵고 비효율성과 중복 작업이 발생할 수 있습니다.
그리고 의사 [12:53] 결정 지연 등의 단점도 존재합니다. [12:56] 반면에
수직적 계층적이 아키텍처 같은 경우에는 어 리더 에이전트가 상위의 방향을
지시하고 하위 에이전트가 그 지시에 따라 움직이는 계층적 구조입니다. [13:08]
각 에이전트의 역할이 명확하게 정의되어 있어서 분담이 명확하고 어 순차적으로
워커플로에 최적화되어 있다는 장점이 있습니다. 어 문서 생평이나 뭐 업무
승인 등 단계는 [13:20] 업무 처리에 적합하다고 볼 수 있습니다.
하지만 리더에 대한 과도한 의존이 있어서 경목 현상을 유발할 수
있고 그다음에 리더 에이전트가 고장날 경우에는 전체 시스템이 마비될 수도
[13:33] 있습니다. [13:35] 네. 이러한 뭐 시스템 패턴이 있는데 어
만약에 LM 모델이 정말 똑똑하다고 하면 네트워크 형태로도 쓸 수
있을 것 같은데 사실상 어 엄청 [13:47] LLM 똑똑한 LM
오픈 모델로 사용하려고 하다 보면은 GPU 메모리가 많이 필요한 부분에
있어서 어 작은 메모리로도 좋은 성능을 내려고 한다고 하면이 수직적
계층적 [13:59] 아키텍처가 조금 저는 더 좋다고 생각을 하긴 합니다.
어, 그다음에이 에이전틱 레그에 대해서 설명하도록 하겠습니다.이 에이전틱 레그는 어,
[14:09] 앞서 말씀드렸던 뭐 이런 아키텍처를 이용한 하나의 방법인 하나의
그 예시인데 뭐 기존 레그 시스템에서 [14:17] AI 에이전트를 더해서
어, 조금 더 똑똑하고 유연한 그 레그를 만들었다고 한다고 생각하시면
될 거 같습니다. [14:28] 네. 그래서 에이전트 레그 아키텍처도 좀
몇 가지가 있는데 우선 싱글 에이전트 레그가 있습니다. 이거는 이제
일종의 라우터처럼 동작을 [14:39] 합니다. 어 즉 최소 두 개의
휴향의 외부 지식 소스가 존재를 하고 에이전트는 현재 상황에 맞게
어느 소스로부터 추가 컨텍스트를 가져올지 [14:49] 판단합니다. 이때 외우지식 소스는
단순히 벡터 데이터베이스에 곱한되지 않고 어 뭐 툴를 이용해서 더
다양한 정보를 접근할 수 있습니다. 여기서도 [14:59] 이제 벡터 서치
엔진이 있고 뭐 캘큘레이터, 웹서치, 맵 검색 이런 다양한 툴을
갖고 와서 이런 것들을 기반으로 리스폰스 하는 형태로 볼 수
[15:09] 있습니다. [15:12] 멀티에트 레그는 이제 어 하나의 에이전트가 혼자서
처리해야 된다라는 있다. 있었다고 하면은 하나의 에이전이 단일 에이전트 [15:23]
시스템에서는 이러한 멀티에이전트 레그 같은 경우에는 여러 개의 에이전트를 조합해서
다중 에이전트 레그 어플리케이션을 겨우 유용하게 할 수도 있습니다. 예를
들어서 여러 전문 [15:36] 검색 에이전트를 조율하는 마스카 에이전트를 두는
방식이 있고 뭐 예를 들어 한 에이전트가 내부 독점 데이터
소스에서 정보를 검색하는데 특화될 수 있고 뭐 다른 에이전트는 뭐
이메일 [15:47] 등 뭐 이런 개인 정보 기반으로 접근하는데 설계되고
또 다른 하나는 뭐 웹에 하는 역할을 맡고 이렇게 각각
에이전트들이 다양한 역할을 맡게 [15:58] 되고 어 그 각 에이전트가
특화된 검색 영역을 담당해서 마스터 에이전트가 이들을 조율함으로써어보다 정확하고 풍부한
답변을 생성할 수 있도록 할 수도 있습니다. [16:11] 네. [16:13]
어 멀티에전트 레그는 다양한 어 뭐 방 아키텍처들이 있는데 뭐
휴맨인 루프라고 해서 말 그대로 AI나 에이전트 시스템이 작업을 수행할
때 [16:25] 사람이 중간에 개입하는 방식입니다. [16:28] 즉 모든 작업을
AI가 자동으로 처리하는 것이 아니라 어 중요한 의사 결정이나 민감한
정보 접근에 있어서는 이제 사람이 직접 확인할 수 있도록 [16:38]
하는 것입니다. 이렇게 해서 여기 보시면 하나는 뭐 커리 에이전트
같은 경우에는 벡터 서치, 웹서치를 통해서 뭐 정보를 갖고 오고
그다음에 또 [16:49] 다른 하나는 유저 기반으로 해서 좀 민감한
데이터를 갖고 오는데 어 가져올 수 있도록 유저가 좀 개입되는
형식으로 볼 수 있습니다. 그것들의 정보를 기반으로 이제 투퍼바이저 [17:00]
에이전트가 정보를 받고 리스폰스 해 주는 형태입니다.이 이 휴맨 같은
경우에는 이제 민감한 정보보호와 정확성 향상이 유리하지만 자동화 속도와 효율성은
떨어지는 단점이 [17:13] 있습니다.이 쉘드 툴스 같은 경우에는 어 이제
여러 에이전트가 하나의 도구를 함께 사용하는 구조입니다. 어 장점으로는 [17:23]
이제 조 도구의 재사용성이 높아지고 그다음에 뭐 에이전트간 경량 협박
구조 구성이 가능한데요.이 이 경량의 협 구조라는 것은 복잡한 메시지
[17:33] 교환이나 스케줄 없이도 그냥 각각의 에이전트들이 독립적으로 알아서 필요한
데이터를 갖고 와서 어 슈퍼바이저 에이전트한테 전달해 주기 때문에 그런
부분에 있어서 조금 더 협업하기가 [17:46] 쉽다라는 이야기입니다. 하지만 단점으로는
이제 동동일독으로 동시에 쓰면은 이제 컨트가 발생할 수도 있고 어
컨텍스트 뭐 충돌로 이제 정확성 [17:56] 저하도 일어날 수 있습니다.
[17:58] 어, 그다음 또 예시로는 뭐 sh드 데이터베이스 with differentols
같은 각도 있는데 이거 경우에는 이제 하나의 데이터 소스를 여러
에이전트가 서로 [18:08] 다른 방식으로 처리하는 구조입니다. [18:12] 어, 해서
뭐 각각의 이제 가져올 수 있는 툴들이 있고 그 툴들을
어, 갖고 온 다음에 뭐 복잡하게 다양한 데이터를 이제 다양한
관점에서 [18:23] 해석 가능하다라는 좀 장점이 있습니다. 하지만 어 에이전트
간의 이제 데이터를 가져오는 부분에 있어서 어 결과가 좀 불일치할
수 있어서 [18:35] 데이터 정합성 유지가 좀 어려울 수 있다.
뭐 이런 단점이 좀 있을 수 있습니다.이 이런 것뿐만 아니라
정말 다양한 멀티에트 레그의 아키텍처들이 [18:45] 있고 어 이제 이런
것들을 어 저희 제가 말씀드린 것 것들을 이제 기반으로 해서
이제 만들면 되는데 이것을 좀 만들기 쉽게 해 주는게 [18:56]
바로이 랭그래프입니다.이 이 랭그래프 같은 경우에 복잡한 AI 에이전트 시스템을
만들기 위해 위한 이제 프레임워크로 [19:06] 전체 작업 풀을 이제
그래프 구조의 노드와 엣지로 표현을 하게 됩니다.이 구조를 활용하면 여러
에이전트가 각자 역할을 막아 협업할 수 있는 유연하고 [19:18] 확장
가능한 이제 워크 플로우를 쉽게 구성할 수 있습니다. 여기에서 예시로
이제 레그를 그려 놨는데 뭐 쿼리가 [19:27] 들어가면은 어제레트 커리퍼스
그러니까 뭐 그냥 일반 답변을 해야 되는 거와 아니면은 리트리버
검색기를 좀 찾아야 되는 것들로 이제 나눠서 라우터 [19:40] 부분이
패턴이 들어간 거죠.이 라터가 이제 확인을 하고 어 일반 답변이면
그냥 바로 답변을 하고 답변이 아니라 이제 뭔가 검색기가 필요하다라고
[19:50] 하면은 이제 검색기에 들어가서 관련된 문서를 가져오고 이런 구조를
보실 수 있습니다.이 [19:59] 랭그래프 요소는 어 노와 H엣 관리이
세 가지가 가장 주요 요소인데요. 노 같은 경우에는 이제 각
노드는 하나의 [20:09] 기능을 수행하는 AI 에이전트어나 이제 외부도그로 구성이
됩니다. 배지 같은 경우에는 어 에이전트 간의 [20:18] 데이터 흐름을
제어하고 조건 상하 경기를 통해 원래 [20:34] 네어 아무튼 그
조건 분기를 통해 상황에 따른 다른 노드로 이동하는 동적인 의사
결정이 가능합니다.이 이 상태 관리 같은 경우에는 어 워크플로 [20:46]
전반에 모든 에이전트가 공유하는 컨텍스트 저장소라고 생각하시면 됩니다. 제이슨 형식으로
이제 정보를 유지하고 작업 흐름을 추적하게 됩니다. 어 그래서 여기에
보이시는이 [20:58] 네모 박스가 하나의 노드라고 생각하시면 될 거 같고요.
이것들을 점점점이 선으로 연결한 것들이 엣지라고 생각하시면 될 거 같습니다.
[21:08] 어, 제가 간단하게 랭그래프 실습을 좀 진행하려고 합니다. [21:14]
네. [21:16] 내용이 사실상 그렇게 어렵지 않아서 잘 따라왔을 거라고
생각합니다. [21:24] 네. 네. 우선 제가이 방금 보여 드렸던 그
링크가 결국에 제가 이렇게 적어 놓은 내용인데 그 관련된이 [21:34]
주피커 파일은이 채팅창에 올려 놨으니까이 채팅창에서 어 파일 다운 받으셔서
하시면은 직접 에이전트 레그를 구현해 보실 수 [21:45] 있습니다. 어,
우선이 튜토리얼에서는 이제 검색들 사용된 문서를 가져와서 사전 처리를 하고
그다음에 어,이 에이전트 레그 시스템을 구축한다고 [21:57] 보시면 됩니다. 아까
전에 제가 그 랭그래프에서 보여 드렸던 이거를 이제 구현을 하는
코드라고 생각하시면 됩니다. [22:10] 네. [22:15] 그래서 한번 진행해 보도록
하겠습니다. 우선은 어이로드 ENB를 이용을 해서 이제 오픈 API 키를
미리 저는이 여기 파일에다가 저장을 [22:26] 해 놓고 요것들을 이제
불러와서 자동으로이 오픈 API 키가 설정되도록 할 수 있습니다. 그리고
나서 첫 번째로 해야 될 거는 이제 [22:36] 문서 사전
처리를 해야겠죠. [22:39] 저는 웹베이스 로더를 이용해서 이제이네 가지의 어
웹페이지에서 어 랭체 사용할 수 있는 더큐먼트 객체로 바꿔 주는
어 바꿔 [22:51] 줬습니다.이 웹베이스 로드를 이용하면은이 웹페이지에서 알아서 갖고
와서 어 관련된 안에 있는 내용들을 이제 더큐멘트 객체로 바꿔
주거 줍니다. [23:02] 그래서 여기에 지금 실행을 한번 해 보게
되면은음 [음악] 여기 이제 보시는 것처럼 첫 번째 [23:13] 문서가
불러온 거죠. 어, 여기 안에 사이트 들어가면은 그냥 에이전틱 AI란
무엇인가 뭐 여기에 대한 설명 블로그거든요. 여기에 대해서 이제 타이틀도이
[23:25] 웹베이스 로더가 알아서 갖고 오고 그다음에 디스크립션도 제가 적어
주지 않아도 어이 AI 자체가 이제 그 웹 문서를 파악해서
디스크립션도 적어 [23:36] 주게 됩니다. 그래가지고 에이전틱 AI에 대한 뭐
내용 이런 이렇게 적어 놓은 거죠. 그다음에 랭귀지도 한글로 인식하고
있다라는 것을 보여 줍니다. 그래서 관련된 뭐 문서도 뭐 [23:48]
이런 식으로 좀 안에 있는 내용도 볼 수 있고요. 그다음에
얘네들을 이제 조금 더 작은 펑크로 나눠서 벡터 저장소에 이제
인덱싱을 하게 됩니다. [24:00] 이때 사용되는 거는 이제 리시브 캐릭터
텍스트리터를 이용을 해 가지고이 하나의 긴 문서를 짤 이렇게 좀
약간 되게 짧게 짧게 어 자른다고 [24:13] 생각하시면 됩니다. 여기서는
지금 리컬시브 캐릭터 텍스플리터를 이용해서 청크 사이즈 200 어 청크
오버랩 50을 줬는데이 뜻은 결국에는이 청크 [24:23] 사이즈 200자를 넘지
않도록 자르되 최대한 자연스럽기 경계로 따른다는 말입니다. 그래서 이렇게 좀
다른 내용들을 보게 되면은 [24:35] 여기이 에이전틱 AI이 문서를 갖고
오는데여 이런 식으로 이렇게 잘라져 있는 것을 볼 수 있습니다.
뭐 에이전틱 AI란 어 지금이 부분은이 [24:46] 약간 좀 어
좀 안에 핵심 내용은 아니고 옆에 사이드에 있는 뭐 광고글
같은데 뭐 이런 것들도 이제 갖고 와서 이렇게 쪼개진 것을
볼 수 있습니다. [24:57] 네. 여기 전체네 개의 문서에 대해서
다 잘라져 있고. 네. 그리고 뭐 이런 식으로 또 볼
수 있습니다. [25:05] 안에 내 연결을. 네. 그다음에 얘네들을 기반으로
해서 리트리버 도구를 만들면 됩니다.이 리트리버는 이제 결국에 벡터 스에다가
저장을 [25:16] 하고 얘네들을 검색기로 갖고 오는 거거든요. 네. [25:23]
제가 그래도 어 이해가 되시는지 좀 궁금하긴 하는데 어 아무튼
어 우선은 이제 문서를 [25:34] 분할했으니까이를 인베딩화를 시킵니다. 어 얘네들을
어 벡터 저장소에 이제 저장을 하게 되고음 이때는 이제 오픈해야
인베딩 [25:44] 모델을 그냥 갖고 왔고 그다음에인 메모리 벡터 스토어라고
어 그냥 그 램에다가 저장하고 어 유사한 벡터들을 검색해 주는
간단한 벡터 [25:55] 데이터베이스입니다. 보통 현업에서는 이제 뭐 크로마디 아니
바이스 아니면은 그 외에 이제 유료 버전의 이런 어 벡터
저장소를 좀 이용을 [26:07] 하고 있는데요. 우선은 여기선 실습이니까 그냥
랭기반에다가 이제 빠르게 저장을 하고 어 블록이 됩니다. 그래서 과정을
보시면 텍스트 문서를 어 쪼개고 그다음에 인베딩 [26:18] 벡터로 벡터화시킨
다음에 메모리 기반 조정소에다가 지금 저장을 하고 검색기 규체를 생성을
하게 됩니다. 지금 여기 벡터 스토어 S 리트리버가 이제 [26:28]
검색기제로 생성을 한라고 보시면 됩니다. 그리고 니들을 어 크리에이트 리티버
툴이라고 하는 어 약간 랭체 [26:37] 툴 생 함수 중에
하나로 이렇게 바로 이제 툴 래핑을 해서 에이전트가 사용할 수
있도록 만들어 주는 줄 수 있습니다. 그러면은 이런 식으로 [26:48]
저는이 리트리버를 하나의 툴로 볼 거고 얘에 대한 네임은 리트리버
블로그 포스트가 뭐 검색하는 거죠. [26:57] 블로그 포스트를 검색하는 거고
어 얘한테 설치 그러니까 한번 얘한테이 블로그를 서치할 건지 아니면
그냥 어 바로 답변을 할 건지에 대해서 이런 [27:08] 식으로
만들 수가 있습니다. 그러면이 디스크립션 보시면은 어 당연히 search 앤
returnation of이 해서 제가 써 놓은 [27:16] 디스크립션이 나오게 되고
이런 것들을 기반으로 어 이제이 툴을 검색기에다가 허리로 제가 뭐
에이전틱 AI [27:27] 이전 모델과의 차별되는 주요 기능을 했었을 때
그 웹사이트에서 이제 관련된 문서를 불러오는 것을 알 수 있습니다.
에이전틱 AI 이전 모델가 [27:38] 차별되는 주요 기념.이이 이이 문서가
결국에는 이렇게 청크돼서 인베딩화된 문서들 중에 가장 유사한 이들이 갖고
이제 불러워졌다라고 [27:48] 보시면 될 거 같습니다. [27:52] 그리고 나서
이제 쿼리를 생선하게 되는데 어 여기에서는 이제 어 레그 그래프를
위한 이제 컴포넌트 노드와 엣지를 이제 구축을 해야 [28:03] 됩니다.
어, 이때 제가 아까 말씀드렸던 그 스테이트 그 랭그래프에서는 스테이트하고
LMR하고 툴이 가장 어, 아, 랭그래퍼드 [28:14] 노드, 엣지, 스테이트가
가장 주요소라고 말씀드렸잖아요. 그럼 거기에서 이제 상태 관리 스테이트 부분을
이제 정의를 해 주게 되고 그다음에이 메시지 스테이트라는 그래프 [28:26]
상태를 기반으로 작동을 하게 되고 어 그다음에 우선은 이렇게 제너레이트
커리올 리스폰스라는 노드를 구축을 하게 됩니다. 여기에서이 노드는 어 [28:38]
LM이 보고 이제 입력된 메시지를 보고 리트리버 도구를 사용할지 혹은
사용자에게 직접 응답할지를 판단을 하게 됩니다. [28:49] 여기에서 어 주요한
점은 이제 이전에 생성한 리트이버툴을 점바인드 툴이라는이 함수를 통해서 채팅
모델에 연결해 줄 수 있습니다. 그리고 [29:00] 이니체 모델 같은
경우에는 우선은 그냥 그 모델을 불러오는 건데요. [29:05] 오픈 API
모델을 오픈 AI 그 GPT 4.1 1 버전을 이제 모델을
불러온 거고이 모델 불러온 거에 어 [29:15] 바인드 툴 해
가지고 리트이버 툴 아까 전에 검색기 툴 얘네들을 얘를 이제
하나의 툴로 붙여 줘서 이제 메시지를 받아오면은이 메시지를 [29:26] 가지고
리스폰스 할 수 있도록 하는 하나의 노드라고 생각하시면 될 거
같습니다. [29:33] 그래서 이거를 한번 실행시켜 보게 되면은 지금이 컨텐츠에
제가 헬로라고 이렇게 적은 적은 겁니다. 이렇게 헬로라고 적으면은 어
여기에서 이제 [29:43] AI 메시지에 어떻게 도와줄까요를 이게 바나나 하고
있고 만약에 제가 어 조금 어려운 그 블로그에 있는 내용들을
좀 물어보게 된다음에 거기에 [29:54] 이제 커그니션 팀이이 멀케이전트 시스템에
대해서 좀 설명하는 부분들이 이제 그 제가 아까 제네 개의
웹사이트 중에 하나 중에 하나가 있는데 이제 제가 이런 식으로
질문을 [30:06] 이제 입력을 하게 되면은 얘가 툴를 이용을 을해야
된다라는 거를인지를 하게 됩니다. 그래서 툴컬 해 가지고 어이 쿼리를
넣어서 한번 찾아봐야 된다. [30:18] 리트리버 검색을 해야 된다라고이 AI가
확인을 하게 되는 겁니다. [30:26] 네. [30:29] 그리고 나서 이제
다음으로 또 만들 노드 같은 노드가 이제 그레이드 더큐멘트입니다.이 드레이드
더큐멘트 같은 경우에는 어 문서 평가를 하기 [30:40] 위한 노드라고
생각하시면 됩니다. 어 여기서는 이제 출력 스키마인 어 레이드 다큐멘트를
좀 이제 사용을 해서 얘네들이 이제 [30:51] 출력을 할 때
얘 솔노로만 대답을 하도록 합니다. 그러고 나서 여기에서도 이제 LM을
쓰여야 되니까 이제 채치기 4.1 버전을 갖고 오고 [31:01] 어
그레이드 더큐멘트의 한 노드를 이제 보시게 되시면은 어 관련된 퀘션이
들어오고 그다음에 또 관련된 문서 리트리버를 통해서 [31:12] 불러오게 된
관련 문서를 집어넣게 되면은 어이 앞서 여기서 설정해 준 프롬포트대로
이제 여기 들어가게 됩니다. 그래서 여기 보시면은 어 [31:23] 너는
어 관련성이 있는지를 확인해 주는 뭐 체포시야 해서 리 리트리브
어 그 관련기 문서를 여기다가 넣게 되고 그다음에 유저 [31:36]
question션을 넣게 되고 얘네들이 관련성이 있으면 예 아니면 노를 반환을
해 달라고 프롬프트를 넣게 됩니다. 아, 프롬프트를 [31:44] 기반으로 해서
어,이 LM 모델이 어,이 프롬프트를 기반으로 해서 이제 얘네들이 관련된
문서가 예인지 노인지를 판별을 하게 됩니다. [32:00] 그래서 예시로 이제
또 실행을 시켜 보면은 어 이렇게 인풋으로 들어가는데 만약에 제가
아까 전에 물어봤던 그 커그니션 팀이 멀티에전트 시스템에 [32:10] 대해서
뭐라고 얘기했어라고 했었을 때 어 만약에이 툴이 원래는 관련 문서가
이제 검색이 돼 가지고 검색기가 관련 문서를 찾아와서 집어넣어 줘야
되는 건데 여기에 그냥 관련 없는 [32:23] 미아오라고 고양이가 울음
소리내는 부분이 이제 들어가게 되면은 어이 LRM이 보고 아이 컨텐트에
있는이 부분이랑이 퀄리랑 관련성이 없어. 그러니까 [32:35] reite question 그래서
다시 그 퀄리를 재작성해라고 이제 반환을 하게 되고 만약에 관련된
[32:44] 문서가 여기 컨텐츠 안에 있다고 치면은 어 여기 지금
커그니션 팀이 뭐라고 얘기를 했는지에 대한 내용이 들어가 있습니다. 그렇게
되면은 이제 [32:54] 데너리트 엔서 해서 관련성이 있으니까 데너리트 엔서를
하면 된다라고 이제 이야기하는 부분을 볼 수 있습니다. [33:04] 어
그러고 나서 이제 쿼리 리라이트로 가게 되면 리라이트를 할 수
있는 부분이 또 있어야 되잖아요. 그러니까 질문을 썼을 때 그
질문에 대해서 제대로 된 문서를 반환하지 [33:14] 못했으니까이 문이 질문을
조금 재수정하게 되는 거죠. 그래서 여기 봤을 때는 이제 뭐
여기에 프롬프트도 [33:23] 어 조금 더 어 좀 더 좀
더 위즌한 그 어 question션을 좀 더 다시 만들어 줘라.
좀 더 인프해 줘라라고 [33:34] 하는 프로젝트가 있고 거기에 대해서
어 LM 모델이 이제 다시 또 작업을 하는 노드를 확인하실
수가 있습니다. [33:46] 그렇게 해서 얘네들을 리라이트를 하게 되면은 어
여기에 대해서 지금 다시 똑같은 질문을 집어넣었을 때 [33:56] 이리라
question이 impr verion of questioner 되게 조금 더된 버전에 질문을
해 주는 것을 알 수가 [34:06] 있죠. 네. [34:10] 뭐
이렇게 리스더 커버니션 팀의 그 멀티에트 시스템에 대한 관점은 무엇입니까?
뭐 이런 식으로 질문을 [34:21] 하는 것을 볼 수 있습니다.
그다음에 이제 마지막으로 제너레이트 엔서를 노드를 이제 생성을 하는 건데요.
[34:30] 여기에서도 이제 프롬퍼트로 관련된 내용들을 집어넣어 주고 뭐 컨텍스트를
기반을 해서 뭐 퀘션을에 대한 대답을 해 줘. 라는 것과
그다음에 이제 [34:40] LLM 모델한테 이제이 프롬프트를 연결을 해 주고
프롬프트를 집어넣고 거기에 대한 리스폰스를 보는 노드를 보시면 [34:50] 됩니다.
그렇게 해서 봤었을 때 최종적으로 어 이런 식으로 컨텐츠도 올바르게
들어가고 거기에 대한 뭐 질문도 있고 여기에 대해서 답변을 어
[35:01] LM이 제대로 이제 출역하게 되는 것을 확인할 수 있습니다.
그다음에 이제이 위에 거는 이제 하나의 개별적인 건데 이것들을 이제
조립을 할 수가 있습니다. 이런 식으로 [35:13] 랭그래프를 사용해서 어
아까 전에 각각 함수들을 노드로 만들었잖아요.이 노드들을 이렇게 워크플로우에다가 애드
노드 해서 하나의이 노드로 이제 [35:25] 입력을 집어넣게 되고 얘네들을
이제 엣지로 연결을 시켜 주면 됩니다. [35:31] 에서 스카트 하면은
스타트에서 바로이 제너레이터 커리 리스폰스에서 그냥 질문으로 갈 그니까 바로
대답을 할지 아니면은 거기에 대한 관련된 문서를 [35:42] 찾아서 대답을
할지에 대한 그 라우터 부분 그다음에이 라우터가 진행이 되고 난
다음에 툴 컨디션 해서이 툴을 이제 리트리버를 이제 사용하게 되는데
[35:53] 어이 리트리버 만약에 필요하면은 바로 리트리버를 사용을 하게 되고
필요가 없으면은 바로 그냥 출력을 하게 되는 형태로 로 보실
수가 있고 그다음에이 [36:03] 툴로 들어가게 되면이 리트 검색기를 갖고
온 다음에이 검색기를 다시 한번 관련된 문서를 갖고 왔는지를 검사해
주는 그레이드 더큐먼트 노드로 가고이 [36:15] 그레이드 더큐멘트 노드로 간
다음에 이제 제너레이터 엔서 해서 어 제너레이터 엔드가 되는 부분이
있고 만약에 관련성이 없다고 하면은 [36:26] 리라이트 question션 해서 다시
커리 리라이트 하는 부분을 으로 돌아가게끔 하는이 워크플로라고 보시면 됩니다.
그래서 그렇게 해서 데이터를 시각화를 했었을 때 딱이 구조가 되는
[36:38] 거죠. 쿼리가 들어갔을 때 얘가 관련성이 있는 컬인지 아
그러니까 그냥 검색기가 필요한 컬인지 필요 없는 컬인지를 확인한 다음에
툴이 필요하다고 하면 툴 쪽으로 가서 [36:50] 검색을 하고이 검색된
애들이 어 관련성이 있으면은 바로 엔서를 대답을 하고 관련성이 없으면
커리를 리라이트 [36:59] 하는 식으로 이제 랭그래프가 구성이 된 것을
보실 수가 있습니다. [37:06] 그렇게 해서 이제 에이전트 레그를 최종적으로
실행을 하게 되면은네 여기이 그래프를 불러 와서이 [37:16] 그래프한테 이러한
컨텐츠를 줬었을 때 어 대답을 잘하는 것을 확인을 할 수가
있습니다. [37:27] 그 아까 전에 똑같이 어그니션 팀이 뭐라고 얘기를
했어 했더니 AI 메시지로 어 얘는 지금 툴이 필요해. [37:36]
그러니까 검색기가 필요해. 그래서 검색기 이툴를 가져오고 여기에 대해서 멀티에전트
시스템에 대한 커리를 날려서 관련된 문서를 찾고 그것을 기반으로 해서
지금 [37:48] 어 툴 메신저가 메시지가 어 관련된 문서를 이제
찾아온 내용이고요. [37:57] 관련된 문서를 찾아오고 나서 어 그냥 여기서는
리라이트 퀘션으로 한번 더 갔네요. 서성이 없다고 판단을 해서 조금
다시 [38:08] 어 얘가 커리를 위라이트를 해 주고 거기에 대한
답변을 해 준 내용이라고 보시면 될 거 같습니다. [38:18] 네.
이렇게 해서 에이전틱 레그에 대한 간단한 실수까지네 진행했습니다.
------------------------------------------------------------

Transcript saved: /Users/jaesolshin/Documents/GitHub/yt-trans/transcript/AI_Agent_개념,_설계,_개발_이_영상_하나로_끝내드립니다ㅣ5년차_Data_Scientist_현직자.txt

⚡ Generating summary...
Generating summary with gpt-5-mini...
Summary generated successfully
Summary saved: /Users/jaesolshin/Documents/GitHub/yt-trans/transcript/AI_Agent_개념,_설계,_개발_이_영상_하나로_끝내드립니다ㅣ5년차_Data_Scientist_현직자_summary.txt
Summary copied to: /Users/jaesolshin/Downloads/AI_Agent_개념,_설계,_개발_이_영상_하나로_끝내드립니다ㅣ5년차_Data_Scientist_현직자_summary.txt

Transcript copied to: /Users/jaesolshin/Downloads/AI_Agent_개념,_설계,_개발_이_영상_하나로_끝내드립니다ㅣ5년차_Data_Scientist_현직자.txt

✅ Transcription completed successfully!
